% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage[top=2.5cm,bottom=2.5cm,right=2.5cm,left=4cm]{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
 %\geometry{margin=0.5in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information
\usepackage{graphicx} % support the \includegraphics command and options
% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
%\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
\usepackage{times}
% These packages are all incorporated in the memoir class to one degree or another...
%\usepackage{biblatex} 
%\bibliography{Essay}
\usepackage{mdframed}
\usepackage{fixltx2e}
\usepackage{hyperref}
%pictures and figures
\usepackage{caption}
\usepackage{subcaption}

\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{lightpurple}{rgb}{0.8,0.8,1}
\lstset{frame=single,
  backgroundcolor=\color{lightpurple},
  language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\footnotesize\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{black},
  keywordstyle=\color{blue},
  morekeywords={endif,bool},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true
  tabsize=3
}
%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

\newcommand*{\glossfirstformat}[1]{\textbf{#1}}

\usepackage[nonumberlist]{glossaries}
\glossarystyle{altlist}
\renewcommand*{\glspostdescription}{}
\makeglossaries

\renewcommand{\glsdisplayfirst}[4]{\glossfirstformat{#1#4}}
\renewcommand*{\glsnamefont}{\sffamily}
\renewcommand*{\glossarymark}[1]{}

\input{glossary}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The "real" document content comes below...
%\usepackage{pdftex}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 
\pagestyle{fancy} 

\begin{document}

\begin{titlepage}
\begin{center}
\textsc{\LARGE University of Hertfordshire}\\[0.5cm]
\textsc{\Large School Of Computer Science}\\[1.5cm]
\textsc{\Large Modular BSc Honours in Computer Science}\\[1.5cm]
\textsc{\Large 6COM0282 â€“ Computer Science Project}\\[3cm]
\textsc{\Large Final Report}\\[0.5cm]
\textsc{\Large April 2013}\\[3.5cm]
\textsc{\Large A Comparison and Analysis of Multithreading Language and Library Implementations and Features with Respect to Conway's Game of Life}\\[0.5cm]
\vfill
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
E R \textsc{Michniak} \\ 10233252
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Colin \textsc{Egan} \\
\end{flushright}
\end{minipage}
\end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak
\section{Abstract}
The conundrum of which multi-threading language to chose for a parallel algorithm is a choice not to be taken lightly. I have implemented 5 multi-threaded versions of Conway's Game of Life using different languages or libraries to provide an investigation and a discussion into the different features and parallel design methods available. The conclusion to which is based on a contrast and comparison of the implementations centring on core values, satisfaction of which I believe will ensure a well-rounded language or library package. The findings of this report highlight the extreme speed and scalability of the OpenMP API, and the simpleness of Implicit threading protocols. However this was not as flexible as C++ which proved to have an even balance of efficiency, scalability, simplicity, and portability.

The source code files are attached to this submission and a guide for compilation and use can be found at appendix A.20.
\pagebreak
\section{Acknowledgements}
Colin Egan - For all his help and support in making this project.
\pagebreak
\section{Introduction}
With such a large number of choices open to programmers in the context of multi-core programming and writing concurrent code there is no wonder that it can be a bit of a minefield getting started. This investigation is aimed at providing an insight into the relevant features and facilities of popular (and not so popular) multi-threading solutions. Whilst also aiming to provide details of some of the quirks and eccentricities encountered during parallel program design and implementation.

The scope of this project includes a discussion of the procedures involved in designing and implementing parallel code, and the generic features of multi-thread capable libraries. A walk-through of the different code implementations and an analysis based on the {\bf core values} outlined later in this section. It is a concious decision to leave an in-depth discussion about different compilers and interpreters out of this report.
\subsection{Motivation}
Designing parallel code, especially for a beginner, is an activity filled with difficult decisions about how to proceed. At every point in the development cycle the stakes are high, and the overall success of the application depends heavily on decisions made during the design and implementation stage. Most importantly, I believe the likelihood of producing a successful parallel application relies on the decision of what multi-threaded language or library to use. The motivation for this project resides my belief that there is a need for a concise resource that contrasts and compares the benefits and pitfalls of popular multi-threading packages for a parallel problem which is simple and common.
\subsection{Aim}
To compare and contrast multi-threading languages and libraries using Conway's Game of Life as an example of language facilities and features. The overall analysis of a particular implementation will be based around {\bf core values}. The successful satisfaction of these will lead to a conclusion based around the suitability of a particular model for a simple parallel problem. Whilst also conducting an investigation into the process of creating parallel code and the obstacles and challenges that come with it.
\subsection*{Objectives}
\newcounter{saveenum}
\begin{enumerate}
\item Provide a commentary on prototype and research undertaken
\item Investigate and document the steps leading to the creation of a parallel algorithm.
\item Produce code implementations of the Game of Life in various multi-threading packages
\item Produce an analysis using quantitative and qualitative methods
\setcounter{saveenum}{\value{enumi}}
\end{enumerate}
\subsection*{Advanced Objectives}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item Graphical output in real-time.
\item A functional model using either SaC or Haskell
\item Apply Amdahl's Law to gain a figure for calculated speed up.
\end{enumerate}
\pagebreak
\subsection*{Achievements}

\begin{table}[hf]
\centering
\begin{tabular}{|r|l|}
\hline {\bf Objective} & {\bf Status} \\ 
\hline 1 &  Completed\\ 
\hline 2 &  Completed\\ 
\hline 3 &  Completed\\ 
\hline 4 &  Completed\\ 
\hline 
\hline 5 &  Completed\\ 
\hline 6 &  Started \\ 
\hline 7 &  Completed\\ 
\hline 
\end{tabular} 
\end{table}
\subsection{Core Values}
\begin{itemize}
\item {\bf Efficiency} A parallel program must run quickly and make good use of processing resources, that's the whole point! Efficiency will not only examine the speed of an implementation with respect to other implementations but also the overall speed-up, the overheads associated with using certain package directives to make code run correctly, the organisation of the code and how a different structure might perform more quickly or slowly, how compiler optimisation (if it's available) effects performance, and any other issues that present themselves.
\item {\bf Simplicity} A simple algorithm is one that is easy to develop, debug, verify, maintain and extend. This value will investigate how much code has had to be added to ensure proper parallel execution over the sequential version. Also, how much of the initial code structure remains? 
\item {\bf Portability} How easy is it to move from one model to another? How hard is it to re-use existing algorithms and create a second implementation even when there is a different threading model? Do the multi-threading directives translate easily? The degree to which a algorithm is ambiguous with another will describe how portable it is in that context. How flexible is the library or language to different threading paradigms. 
\item {\bf Scalability} Technology is evolving, the number of processors in computers is only going to increase in the future. How scalable is the code produced? Does the addition of more threads provide a continual speed-up in line with the number of independent processors on a machine? If the size of the data set increases what's the overall effect on the programs execution? The degree to which an implementation can maintain a speed-up with the addition of increasing resources or workload will describe its scalability.
\end{itemize}
\subsection{Required Knowledge}
It is expected that the reader has a background in programming, it is not necessary that this background be in the languages discussed in the report. Part of the report is focused around providing a commentary to parallel program design and whilst a knowledge of parallel programming is useful, it is not necessary. A definition of terms can be obtained in the glossary if any definitions are required that aren't provided in the report.
\subsection{Project Structure}
\begin{itemize}
\item An in-depth discussion of cellular automata, in particular Conway's Game of Life in Chapter 4.1
\item A look at the sequential algorithm for Conway's Game of Life in chapter 4.2
\item A discussion of the phases for creating parallel algorithms in chapter 4.2.2.
\item A discussion on the concept and application of threads in the context of programming languages in chapter 4.3
\item Chapter 5 chronicles the implementation.
\item Chapter 6 begins to look at testing and analysing the results
\item A conclusion based on the findings is in Chapter 7
\item Chapter 8 consists of the Bibliography and The references. Followed closely by the Appendices and a Glossary of Terms.
\end{itemize}
\subsection{Test Setup}
There is a significant amount of testing that will take place. Throughout the implementation and analysis stage, to test stability, efficiency and scalability.
\smallskip
\\My test platform:
\begin{itemize}
\item Intel Q6600 at 3.0GHz
\item 6GB of DDR2 at 800MHz
\item Linux Mint 14 x84-64
\end{itemize} 
Compilers, interpreters and runtime environments used:
\begin{itemize}
\item \gls{GCC} - GNU C Compiler
\item G++ - GNU C++ Compiler
\item Javac - Java Compiler 
\item Python2.6 - Python interpreter
\item GCCGO - Go compiler with a GCC backend
\item Go - Go Compiler
\end{itemize}
\section{Background Research and Algorithm Design}
\subsection{Life}
Conway's Game of Life is an example of a {\bf cellular automaton} (CA). This is described \cite[p6]{ref6} as a ``discrete dynamical system which evolves by the iteration of a simple deterministic rule''. When considering constructing a CA there are a few steps one has to follow:
\begin{itemize}
\item Firstly, consider that \emph{time is discrete} and progresses in steps, in this report I will mostly be referring to them as {\bf generations}. A term far more fitting for Conway's Game of Life. 
\item Secondly, an \emph{n-dimensional space} is divided and sectioned into {\bf cells}. This space will have a boundary condition associated with it. I will be implementing the space with an orthogonal toroidal array in 2-dimensions. This means that my boundary conditions would be {\bf cyclic} rather than {\bf absorbing}. {\it figure 1}
\begin{mdframed}
{\bf Extension Box:} However interesting and challenging it may be to implement the Game of Life in 3-D space it is not the focus of this project and for the sake of thread workload scheduling, clarity, and correctness of the result, 2-dimensions is safer and more predictable.back
\end{mdframed}
\item Thirdly, each cell has an {\bf attribute} from a limited set of attributes. In the case of Conway's Game of Life, each individual cell can either be dead or alive. Represented in most of my implementations by a 1 or 0. The combined values of all cells in the space are considered to represent the {\bf global state}.
\item Finally, to progress to the next time interval (for instance, to progress from t\textsubscript{0} to t\textsubscript{1}) a {\bf transitional function} is applied to each individual cell using its attribute and the attributes of its {\bf neighbourhood}. Such that, t\textsubscript{1} is the state of the automaton after having the function applied at state t\textsubscript{0}. In this context the Game of Life uses a \emph{Moore-neighbourhood} which consists of the 8 cells surrounding a central cell. However it is worth to note the existence of the \emph{Von Neumann neighbourhood} which pre-dates Moore's implementation. {\it figure 2}
\end{itemize}
\begin{figure}[h]
        \centering
        \begin{subfigure}[h]{0.3\textwidth}
                \centering
                \includegraphics[scale=1]{cyclic}
                \caption{Cyclic boundaries}
                \label{fig:cyclic}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[h]{0.3\textwidth}
                \centering
                \includegraphics[scale=1]{absorbing}
                \caption{Absorbing boundaries}
                \label{fig:absorb}
        \end{subfigure}
        \caption{Types of boundaries}\label{fig:boundaries}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[scale=0.75]{neighbourhood}
\caption{The two types of CA neighbourhood}
\label{fig:neighbourhood}
\end{figure}
Considered by many to be a \emph{zero-player game}, Conway's automaton was first revealed in a 1970 Scientific American article \cite{ref7} where his rules where enumerated and an explanation of how one might play his game was offered. This involved a very laborious method of using a checker board and some two-colour checkers (or something similar), to represent the {\bf global state} and every cells individual attribute. An 8 x 8 grid would require 64 applications of the transitional function to move forward just one generation! Maybe you can begin to see why a computational implementation would be useful?
\subsubsection*{The Laws of Life}
\begin{enumerate}
\item Survivals. Every live cell with two or three neighbouring live cells survives for the next generation.
\item Deaths. Each live cell with four or more neighbour live cells dies (is removed) from overpopulation. Every live cell with one neighbour or none dies from isolation.
\item Births. Each dead cell adjacent to exactly three neighbour live cells--no more, no fewer--is a birth cell. A life is placed on it at the next move. (i.e. the cells attribute is changed) \cite{ref7}
\end{enumerate}
These laws are going to form the basis of the {\bf transition function} which will be applied to the grid to progress to the next generation.\\
\\What makes the Game of Life so interesting and unique? In the book ``The Game of Life: Cellular Automata'' \cite[p1]{ref8} argues that it is ``...the discovery of ``oscillators'' (periodic forms) and ``gliders'' (translating oscillators).'' that are the source of its original fame and interest. These {\it lifeforms} represent a breakthrough in two-dimensional cellular automata and were discovered by mathematician William Gosper in 1970. A prize was offered by John Conway relating to his conjecture that there could be a configuration of the initial state that would constantly promote an ever increasing number of live cells in the global state. Gosper won the prize by demonstrating, and thus coining the term, a glider gun. {\it figure 3}\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{gosper}
\caption{The Gosper Glider Gun}
\label{fig: Gosper}
\end{figure}
\\Why code? Even smallest grid requires a lot of time and effort to move from one generation to the next. Consider the configuration in {\it figure 3} and try to process a single generation using a manual method. Boring, repetitive and tedious isn't it? Thankfully computers excel at boring and repetitive tasks that humans find tedious. Also, it's interesting! There's no end to the different implementations that could be written to change some way in which the system executes. Finally, the most common implementation of the Game of Life would involve the allocation of some array structure, and considering the layout of computer memory this is very intuitive and easy to do.\\
\begin{figure}
\begin{mdframed}
{\bf Extension Box:} There is a vast number of different algorithms that could be implemented. For example, Hashlife, quad-trees, linked-list, bit-stream... An extension could be researched into the relative performance of different algorithms in specific languages and the language features which benefit or hinder execution. My pseudo-algorithm will be outlined later on however I will be focusing on realising and defining parallel points in the program execution and discussing the syntax, semantics and effectiveness for respective implementations.
\end{mdframed} 
\end{figure} 
\subsection{Prototype Code, Parallelism Research and Algorithm Development}
A prototype sequential version of the Game of Life has been produced as part of my research into the algorithms available and memory structures I could have used. This version has been produced in C and can be broken down into a few abstract, yet simple, operations. This example is an illustration of one of the most basic of programming paradigms, {\bf sequential composition}. This is described by \cite[p68]{ref9} as when components are executed in order, one after the other. The composition terminates when the last component terminates. Considering components as individual sub-programs or functions in our C code. We can begin to see how the Game of Life may be executed sequentially. And quite slowly for that matter! Referencing {\it figure 4} we can see the {\bf sub-programs} or {\bf components} that make up the sequential algorithm for the Game of Life. I will talk about some of the more interesting and prominent snippets of code from this early implementation, however a full listing will be available, line-numbered and commented, in the appendix A.1.\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{sequential0.png}
\caption{A context-level activity diagram of the Game of Life algorithm}
\label{fig: Algo0}
\end{figure}
\\This is the starting point for the entirety of the project. From this diagram I can get an overview of how one algorithm is different from another and construct new algorithms. By changing {\bf sub-programs}, by modifying {\bf program transitions}, and by delving deeper into {\bf components} and their constituents. The most important aspect of this diagram is going to be helping me realise and program the parallel regions of the automaton.
\subsubsection{Refactoring the Components}
{\it Figure 4} highlights that the first process in the Game of Life algorithm to take place is the allocating of memory for the array. Consistency across my code modules is paramount and {\bf DIM} references the chosen dimension of my game board. I need two identically sized blocks of memory to represent my two-dimensional grid. One for the current state, and one for the state of the next generation. As shown in {\it figure 4} at the end of an iteration of one generation the references to the grids are swapped, and the process repeats itself until {\bf MAXGEN} is reached. 
\begin{mdframed}
{\bf Knowledge Box:} The '{\bf \#}' symbol denotes a {\bf preprocessor macro}. I have used these extensively in my prototype code. It is a way of instructing the compiler, if certain conditions are met, which code to include or exclude from compilation. This is known as conditional compilation. It is especially useful, in the case highlighted below, when experimenting with different types as some blocks of code may stay the same however the prototypes or function declarations may change. Initially a {\bf macro} is defined at the top of the program and then tested in the main code block. This can be seen in appendix A.1 lines[12,13], lines[26-34], and lines[147-151].
\end{mdframed}
\bigskip
\begin{figure}[h]
\begin{lstlisting}[language=C,caption={Array allocation using {\it malloc}, {\it calloc}, and {\it bool}}, morekeywords={malloc,calloc,bool}]
#if USEBOOL == 0
    #if MALLOC == 1      
        grid = (int **)malloc(sizeof(int *) * DIM + 2);
        new_grid = (int **)malloc(sizeof(int *) * DIM + 2);
        
        for (i = 0; i < DIM + 2; i++)
        {
            grid[i] = (int *)malloc(sizeof(int *) * DIM + 2);
            new_grid[i] = (int *)malloc(sizeof(int *) * DIM + 2);
        }            
    #else        
        grid = (int **)calloc(DIM + 2, sizeof(int *));
        new_grid = (int **)calloc(DIM + 2, sizeof(int *));
        
        for (i = 0; i < DIM + 2; i++)
        {
            grid[i] = (int *)calloc(DIM + 2, sizeof(int *));
            new_grid[i] = (int *)calloc(DIM + 2, sizeof(int *));
        }            
    #endif
#else
    grid = (bool **)calloc(DIM + 2, sizeof(bool *));
    new_grid = (bool **)calloc(DIM + 2, sizeof(bool *));
    
    for (i = 0; i < DIM + 2; i++)
    {
        grid[i] = (bool *)calloc(DIM + 2, sizeof(bool *));
        new_grid[i] = (bool *)calloc(DIM + 2, sizeof(bool *));
    }
#endif
\end{lstlisting}
\end{figure}
In {\it listing 1} we begin to understand the plethora of options that are open to implementation in the considered context of {\bf array memory allocation} (We haven't even considered any of the other memory structures!). The general convention for all 3 blocks of code is the same, that we need to allocate a memory block for each of our pointers, {\it grid} and {\it new\_grid}, to address. The only things that change are the functions used for allocation, {\bf malloc} or {\bf calloc}, or the parameter passed to {\bf sizeof}.
\begin{itemize}
\item {\bf Malloc} will take one argument, the size in bytes of the memory to allocate. It returns a void pointer to the block of memory which is then cast to the type that we wish to use. In the case of line 3 it is the pointer to a pointer of int values. 
\begin{mdframed}
{\bf Example: }This chain of pointers is necessary as we need a two-dimensional array. Each index is calculated as an offset from the base address referenced by the pointer. For example grid[2] is 2 times the size of an int pointer away from the base address of the grid pointer. If {\it \&grid} is 0x10 then {\it \&grid[2]} will be 0x90, assuming a pointer size of 4 bytes.
\end{mdframed}
\item {\bf Calloc} will take two arguments, the number of array elements to allocate, and the size of each individual array element. This also returns a void pointer which has to be cast to a desired type. However, there is a difference in the behaviour of the function. Calloc will zero-initialise the memory allocated. Whereas malloc will not initialise any memory in the allocated block, the indeterminate values will remain. 
\item {\bf Bool} is a data type most Java programmers will be familiar with, however it was not included in the standard revision of C until the release of C99. To this day the {\bf bool} header file has to be included in the C program by a preprocessor macro as indicated by appendix A-1 line 6. 
\item {\bf Sizeof} is a function that returns the size of its parameter in bytes. Extremely useful in maintaining portability of C code across different architectures. This is because the compiler will know what the size in bytes of an Integer is on its system...probably better than the programmer.
\end{itemize}
\begin{mdframed}
{\bf Knowledge Box:} Type-safety really takes the back-seat when programming in C! When we say something is {\bf type safe} we mean that the language guarantees that a value of one type can't be incorrectly used as if it were another type. This makes C very type {\bf unsafe}! Casting a pointer to another type allows the programmer to use it as that type even though the actual value could mean absolutely nothing. Also the function {\bf free} allows the programmer to deallocate memory and reassign a pointers and possibly use them later. The concept of {\bf casting} and {\bf dangling pointers} means that C can never be type safe! \cite[Type Safety]{ref11}
\end{mdframed}
\bigskip
After the array is allocated the next step in the Game of Life algorithm is to assign an initial global state to the grid by {\bf randomly spacing life forms in the array}. In the sequential program this is done by choosing a probability of life existing and randomly (not actually random at all - but that's another project!) placing live or dead cells. The function in {\it listing 2} iterates through the array using nested for-loops. Remember the allocation of the memory from the last code snippet? The parameters given to the malloc or calloc functions are DIM + 2 in size each time! This is because of my design decision to use a orthogonal toroidal array, which gives the grid cyclic boundary conditions. The grid has to have an extra 2 rows and an extra 2 columns to house the {\bf ghost cells} which will be explained shortly.
\begin{lstlisting}[language=C,caption={Randomly spacing lifeforms in the array}, morekeywords={malloc,calloc,bool}]
#if USEBOOL == 1
void fillRand(bool **grid_ptr)
#else
void fillRand(int **grid_ptr)
#endif
{
	int i, j;
	srand(SEED);

	cell_count = 0;
	life_count = 0;

	for (i = 1; i <= DIM; i++)
	{
		for (j = 1; j <= DIM; j++)
		{
			if (rand() % LIFE == 1)
			{
				life_count++;
				grid_ptr[i][j] = 1;
			} else {
				grid_ptr[i][j] = 0;
			}
			cell_count++;
		}
	}
}
\end{lstlisting}
However, in these loops we only care about the cells relating to the global state, so the iteration bounds are set at 1 and less than or equal to DIM respectively. Notice line 8, here the random function that's used on line 17 is seeded with a preprocessor defined value. This is to ensure that the random set returned will always be the same. Keeping the same input data and confirming by a replicable result is vital at this stage to confirm the correctness of the code. On line 17 the value returned by the {\it rand()} function is used as input to a modulus function with the macro {\it LIFE} which defines the probability of life occurring. In this case, if LIFE were to equal 3, then the approximate number of live cells would be equal to the total number of cells divided by 3. Also notice the preprocessor macro around the function declaration which will change the type of the parameter accepted.\\\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{sequentialGhost.png}
\caption{A Level 1 Activity Diagram of the copying ghost cells process}
\label{fig: Algo1}
\end{figure}After the initial global state has been defined we can begin the main game loop! That brings us on to the {\bf copying of the ghost cells}. As mentioned before, cyclic boundary control means that the grid will perform as if it were laid out over a toroid. This allows such lifeforms as translating oscillators (like the glider mentioned in section 3.1) to continue infinitely as long as they are not obstructed by another live cell. At the beginning of each generation the columns at index [i][DIM + 1] and [i][0], and the rows at index [0][i] and [DIM + 1][i], are written to with the attributes stored in columns [i][1] and [i][DIM] and rows [DIM][i] and [1][i] respectively. Where i is any value between 1 and DIM for the first loop and 0 and DIM + 1 for the second. This is illustrated in an abstract manner in {\it figure 5} and in full in {\it listing 3} where lines 4 and 5, 10 and 11, represent the copying of the ghost cells for columns and rows respectively. This change in the range of iteration is so that we can ensure the cells in the corners have a value. A visual example of the memory elements and their values can be seen in {\it figure 1}. 
\pagebreak
\begin{lstlisting}[caption = {Copying ghost cells}]
    /*copy ghost columns to grid */
    for (i = 1; i <= DIM; i++)
    {
        grid_ptr[i][DIM + 1] = grid_ptr[i][1];
        grid_ptr[i][0] = grid_ptr[i][DIM];
    }
    /*copy ghost rows to grid */
    for (i = 0; i <= DIM + 1; j++)
    {
        grid_ptr[0][i] = grid_ptr[DIM][i];
        grid_ptr[DIM + 1][i] = grid_ptr[1][i];
    }
\end{lstlisting}
Now that the initial grid is full to the brim, the program can begin processing the next generation by applying the transitional function for Conway's Game of Life. An abstract view of the algorithm is given by {\it figure 6} where the nested nature of the loops and the decisions based around the logic of the transitional function can be seen causing changes in the state of the array for the next generation. It should be fairly obvious to see how the rules listed in {\it figure 6} conform to the rules enumerated in section 4.1. This algorithm is written out in full in {\it listing 4} with the counting of the moore-neighbourhood taking place from line 12 and the application of the transitional function from line 18. Every rule must write something to the appropriate element of the array for the state of the next generation. this can be seen in line 20, a life being written, line 23, a death being written, or line 26, a survival being written. After this it is simply a case of swapping the grid and new\_grid pointers and incrementing the {\it gen} counter. The game will continue until {\it gen} equals MAXGEN. As mentioned earlier the correctness of my results is vital and a function to count the number of alive cells after the game has finished is also in the code base in A.1. This can be compared against other models to ensure correctness. 

%\begin{figure}[h]
\begin{lstlisting}[caption={Processing the Moore-neighbourhood and writing to the next generations global state array}]
#if USEBOOL == 1
void process(bool **grid_ptr, bool **new_grid_ptr)
#else
void process(int **grid_ptr, int **new_grid_ptr)
#endif
{
	int i, j, count;
	for (i = 1; i <= DIM; i++)
	{
		for (j = 1; j <= DIM; j++)
		{
			count =
			    grid_ptr[i - 1][j - 1] + grid_ptr[i - 1][j] +
			    grid_ptr[i - 1][j + 1] + grid_ptr[i][j - 1] +
			    grid_ptr[i][j + 1] + grid_ptr[i + 1][j - 1] +
			    grid_ptr[i + 1][j] + grid_ptr[i + 1][j + 1];

			if (count == 3 || (count == 2 && grid_ptr[i][j] == 1))
			{
				new_grid_ptr[i][j] = 1;
			} else if (count < 2 || count > 3)
			{
				new_grid_ptr[i][j] = 0;
			} else if (count == 2)
			{
				new_grid_ptr[i][j] = grid_ptr[i][j];
			}
		}
	}
}
\end{lstlisting}
%\end{figure}
\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{sequentialProcessGrid.png}
\caption{A Level 1 Activity Diagram of the application of the transitional function and rule logic}
\label{fig: Algo0}
\end{figure}
These blocks of code have helped me make some fairly crucial design decisions on my C and C++ versions and to a lesser extent my Java and Python versions. Earlier on I introduced the idea of a preprocessor macro and explained my use of them. This has helped me make two big design decisions. Firstly to use the function {\bf calloc} for allocating my array memory, and secondly to use the {\bf bool} import and data-type for the element attributes. There is a small investigation I have conducted into these choices, but due to length constraints they have been resigned to the appendices A.14, A.15, and A.16. 
\subsubsection{A Thought Process for Parallelism}
Why do we make code parallel? So we can increase the speed at which a process or program can execute, of course! There are three main levels of parallelism: {\bf instruction-level parallelism}, {\bf data parallelism}, and {\bf task parallelism}. Where instruction-level parallelism represents instruction pipelining, branch prediction, or super-scalar architectures \cite[p41]{ref10}. Task parallelism is the simultaneous processing of different tasks (or processes). Data parallelism, the beast that I am concerned with, is the decomposition of data into smaller blocks so that work can be carried out on them in parallel by separate processing units \cite[A-17]{ref10}.
\begin{figure}[h]
\begin{mdframed}
{\bf Knowledge Box:} It is important to make a distinction between {\bf parallelism} and {\bf concurrency} even though it is common to use the two terms interchangeably. Concurrency is about dealing with many things at once, whereas parallelism is about executing two or more things at the same time. In concurrently structured programs the design is not automatically parallel. A concurrent task is one that is independent and {\bf concurrent decomposition} deals with breaking a program into pieces that can be executed independently.  Concurrently structured code can be parallel! Although if it is parallel it is a symptom of the environment and not necessarily the code produced. An example of this would be that single-core processors can run code in a concurrent manner, or in a way that may seem parallel even though it is not. \cite{ref12} Thus it is correct to say that parallelism is a subset of concurrency. 
\end{mdframed}
\end{figure}
When we begin to think about realising and adapting the program to run in a parallel manner there are a few design processes and activities to consider before writing. {\bf Partitioning} involves dividing up the program into components that will allow parallelism then {\bf granularity} is adjusting the ratio of computation to communication for these parallel components and then {\bf mapping} this refactored design to computational units. \cite[p77,78]{ref9} A quantitative approach can be achieved by identifying code that {\bf can} be made parallel and code that {\bf can't} be made parallel. The application of this quantitative method is known as {\bf Amdahl's Law}. In the context of the prototype, a prediction on speed-up can be made my analysing the amount of time an entire run of the program spends in the cell processing phase and the amount of time the program spends executing code that can only ever be sequential.
\bigskip
\begin{mdframed}
{\bf Knowledge Box:} Amdahl's Law states that the performance enhancement possible with a given improvement (for instance: creating a parallel region from a serial region) is limited by the amount that the improved feature is used. \cite[p51]{ref10}\\ The formula for calculating a speed-up S for N processors can be explained by:\bigskip

\centerline{$ S(N) = \frac{1}{(1-P) + \frac{P}{N}} $}
\smallskip
Where {\bf P} is the proportion of code that is subject to improvement and can be made parallel.
\end{mdframed}
\bigskip
An analysis of the sequential code using the GNU runtime profiler {\bf Gprof}, shows the amount of time the program spent executing in each function. The call-graph can be a little hard to look at and interpret so I have shown the flat profile in {\it figure 7}. It should be noted that the code has been refactored so that each function represents only one task. This, whilst also being good programming practice, is necessary for Gprof to give a more detailed output. A full listing of the sequential code can be found in appendix A.1 and the full Gprof output in appendix A.2. The function {\bf process()} will call the functions {\bf getCount()} and {\bf applyRule()}. The parameters for this execution of the simulation are 100 generations with a 1024 square grid. This can be observed in the {\bf calls} column where the process function has 100 calls (1 per generation) and both getCount and applyRule have 104857600 calls; 1048576 cells in the grid, 100 times.
\begin{figure}[h]
\caption{Gprof Flat Profile from seqGoL.c}
\begin{verbatim}Each sample counts as 0.01 seconds.

  %   cumulative   self                self     total           
 time   seconds   seconds    calls    ms/call  ms/call  name    

 56.47      1.98     1.98 104857600    0.00     0.00    getCount
 29.95      3.02     1.05 104857600    0.00     0.00    applyRule
 12.90      3.48     0.45      100     4.51    34.76    process
  0.57      3.50     0.02        1    20.06    20.06    fillRand
  0.29      3.51     0.01        2     5.02     5.02    printGrid
  0.00      3.51     0.00      100     0.00     0.00    copyGhostCells
  0.00      3.51     0.00        1     0.00     0.00    init
\end{verbatim}
\end{figure}

From this data an attempt can be made to calculate the expected speed-up for different numbers of processors. Using the values in the {\bf \% time} column of the table one can estimate a value for {\bf P} the proportion of code that can be made parallel. However, it should be noted that when converting a sequential algorithm to a parallel one it is normal for the {\bf problem size} to increase. In this context, this means the addition of scheduling and synchronisation algorithms.
\subsubsection*{Partitioning}
The main concerns here are the ability to maintain {\bf scalability} and {\bf hide latency} when the program is run in a parallel manner. Where scalability refers to the measure of increased performance for an increased number of computational units. And hiding latency is the extent to which the overheads created by an increase of communication and code are hidden by an overall speed-up and increased processing power (by utilising multi-core or multi-computer architectures). \cite[p78,79]{ref9} To address the issues of scalability and latency the initial workload will be {\bf decomposed} into a number of partitions less than or equal to the number of computational units available.\\
%something is wrong with the formatting if this line is removed?
\begin{figure}
\begin{mdframed}
{\bf Example Box:} When talking about hiding latency the concept usually refers to the down-time a processing unit may encounter when it has finished its work or is waiting for information. This is talked about in a more relevant context later in the next section. Here, however, I am referencing the overheads created by that actual inclusion of code that makes parallelism possible. For example, the calculation of the amount of work to schedule each processing unit and the time spent waiting for synchronisation increase overall program latency as it has the possibility of increasing the down-time of a thread or processing unit.
\end{mdframed}
\end{figure}
How do we begin to partition the problem into parallel code? The answer is {\bf domain decomposition}! This involves dividing up the data of the program so that it can be executed in a parallel manner. My most prominent data structure is the set of two-dimensional arrays, one that is read from by the program and one that is written to. So, in the context of Conway's Game of Life, this would mean dividing up the array representing the global state into smaller arrays or {\bf chunks} to signify the work for each individual processing unit to compute. In this case the transitional function could be applied by independent computational units on their respective workloads which have been calculated by decomposing the data domain. However, this highlights the issue of {\bf problem scaling} where the number and size of the chunks created during the partitioning process should be proportionate to the amount of available processing units. This is so to maintain and maximise the performance improvements from parallelising the work. This can be seen in {\it figure 8} where an eighteen-by-eighteen grid representing the global state and ghost cells is decomposed to show the work taken out by individual computational units.
\bigskip
\begin{mdframed}
{\bf Knowledge Box:} As well as {\bf domain decomposition} there exists concepts of {\bf functional decomposition} and {\bf irregular problem decomposition}. Functional decomposition involves decomposing the function of the problem as opposed to the data. Irregular problem decomposition refers to when the program structure cannot be determined before runtime. This could be caused by a dependency to user input data.\cite[p85]{ref9}
\end{mdframed}
\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{DomainDecomposition.png}
\caption{The Global state and how it might be partitioned to support parallel processing}
\label{fig: Para1}
\end{figure}
\subsection*{Granularity}
Granularity is about adjusting the ratio of {\bf communication} to {\bf computation} and it heavily influences the choice of data structure for a parallel implementation. Increasing the locality of the data structures increases the ratio of computation to communication. In a less abstract sense, by separating the input and output data arrays more computation can be completed as less communication is needed by the computational units to arrange synchronisation. This is achieved through using two arrays; one to hold the current global state and one to hold the future global state. The trade off in increased memory usage is worth it considering the speed up.\cite[p87]{ref9} The current approach focuses on a {\bf coarse-grained} structure. Whereby the data sets worked on by each thread are as large as possible and are available through a shared resource that requires little to no communication to access. Imagine if the grid were divided into smaller chunks and each thread handled more of these smaller pieces. Whilst increasing the flexibility of the data processed we have also increased the overheads associated with processing. This {\bf fine-grained} solution will require more synchronisation between threads (imagine the recombining of the processed chunks) and ultimately be slower. In the context of Conway's Game of Life this issue is rarely visible; the components are decomposed to remain independent and so it is wise to process as much as possible to reduce communication and increase computation.
\subsection*{Mapping}
Mapping is the process of assigning components to computational units for execution. It is the final step in creating the parallel algorithm and it brings together all of the processes completed so far. There are many different methods for successfully mapping and I am going to talk about, and ultimately implement, a method of mapping known as {\bf indexing}.\cite[p89]{ref9}

Indexing is most commonly used in domain and functional decompositions and makes use of indexes obtained from the partitioning process to assign work to processing units. In the context of Conway's Game of Life, {\it figure 8} describes how the global state array may be partitioned to allow parallel processing. If each of these partitions is assigned a number representing the index of the thread which is going to be dealing with it then an algorithm can be written that partitions and maps the work accordingly. This is described in {\it listing 5} and written in pseudo code. The {\bf start} and {\bf stop} values refer to global state array rows, the {\bf id} value to the Identifier or index of the computational unit, the thread to which the work is assigned, and {\bf numberOfThreads} the desired level of partitioning.
\begin{lstlisting}[language=C, caption={Pseudo Domain Decomposition and Thread Mapping Algorithm}]
for id = 0; id < numberOfThreads; id++
    start = ((dimension / numberOfThreads) * id) + 1
    stop = (dimension / numberOfThreads) + start - 1
    createThread(id, start, stop)
\end{lstlisting}
The algorithm in {\it listing 5}, when implemented, will provide a facility for decomposing the global state into {\bf partitions} that are assigned {\bf indexes} which are {\bf mapped} to their appropriate computational unit. Using this information, along with the previous version of the activity diagram for the sequential algorithm, it is possible to redefine the diagram with a control flow that resembles the complete Game of Life parallel algorithm. This is seen in {\it figure 9}. Notice the inclusion of a new process {\bf Schedule work based on number of threads}, this refers to the code in {\it listing 5}. Also visible are two black bars referred to as {\bf fork} and {\bf join}, these keywords and the symbols shown here refer to the synchronisation that has to take place to ensure the algorithm runs without fault and will be explained in full in the next section.
\smallskip
\begin{figure}
\begin{mdframed}
{\bf Extension Box:} It is worth noting that the described method of work allocation is known as {\bf static}. In that, the allocation of work to the threads does not change after its initial assignment. There is a concept of {\bf dynamic} work allocation that could also be implemented by the simulation. This could involve an implementation of a work stealing algorithm whereby, if a thread has finished its initially allocated work load, it could steal work off another thread that is still executing. In addition to this a dynamic work allocation algorithm would involve the adoption of a {\bf fine-grained} data structure and along with it the overheads of increased communication.\cite[p16]{ref14} As interesting and challenging as this would be I feel it is out of scope of the project as my main goal is to compare and contrast the implementations of different multi-threading languages and libraries.
\end{mdframed}
\end{figure}
\begin{figure}[h]
\caption{A Level 0 Activity Diagram of the parallel Game of Life Algorithm}
\centering
\includegraphics[scale=0.45]{parallel0.png}
\end{figure}
\subsection{Threads}
%Do I need to say this?
This section will focus on the methods and implications of using threads. Nevertheless I believe a definition is necessary for context. A {\bf thread} is a concurrently executable process unit with access to a {\bf shared memory} space. Being a {\it concurrent} component means that a thread is basically a sequential program by itself. A thread runs by calling functions from code that exists in its shared memory space. Threads are {\bf asynchronous} they run whenever they can, at different speeds, and at different times. They may be delayed, lock or even destroyed for reasons which can be hard to realise. \cite[p70]{ref13} 

\subsubsection{Thread Creation}
One of the aims of this investigation is to look at different types of threading solutions available at the moment. How could I begin any way other than to show a ``Hello World'' example, with a twist of course. For this small introduction I won't be talking about any thread package in a great detail, this is a focus on the different code structures that can arise from different threading strategies. {\it Listing 6} shows a simple C program, this much should be obvious, however there is the addition of 4 lines and a single block encased in curly braces which are providing the basic facility for threading. The first point of interest is line 1, this statement includes the header file for the OpenMP package. A very powerful {\bf implicit} threading API. Line 7 defines two variables one for storing the identifier of any created threads and {\it nthreads} that stores an integer referring to the number of threads for OpenMP to create. Line 8 is a compiler specific directive that indicates the fork point for the OpenMP package. At this point the OpenMP API will create a number of threads indicated by the {\it nthreads} integer, and each thread will have a private field {\it th\_id}. The successful execution of this directive now means that all the code in between the curly braces on lines 9 and 12 will be in a OpenMP parallel region. At this point {\it nthreads} are created and each one attempts to execute the code in the parallel region. The private field {\it th\_id} is used on line 10 where the OpenMP function {\bf omp\_get\_thread\_num()} assigns the threads identifier to the private field. This can be useful to create sequential regions inside parallel ones, however more on this later. The ultimate conclusion of this code is that each created thread executes the {\bf printf()} function on line 11. There you have it, 4 threads, 4 lines of output. Easy, right?
\begin{lstlisting}[language=C, caption={Hello World from OpenMP}]
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
 
int main (int argc, char *argv[])
{
  int th_id, nthreads = 4;
  #pragma omp parallel private(th_id) num_threads(nthreads)
  {
    th_id = omp_get_thread_num();
    printf("Hello World from OMPthread %d\\n", th_id);
  }
  return EXIT_SUCCESS;
}
\end{lstlisting}
\begin{figure}
\begin{verbatim}
Hello World from OMPthread 0
Hello World from OMPthread 2
Hello World from OMPthread 1
Hello World from OMPthread 3
\end{verbatim}
\end{figure}
\subsubsection*{Explicit and Implicit Threading}
That example may seem unnecessarily trivial however there is method in my madness. The explained code in {\it listing 6} is an example of a package which employs an {\bf implicit} threading model. This means that a lot of the creation and management of the threads (even sometimes the scheduling!) is hidden from the programmer to make the entire job a lot easier. The {\bf \#pragma} statement in {\it listing 6}, line 8 is a directive for the compiler to {\bf fork} a {\bf team} of threads. At the end of the parallel region, when all of the statements inside the curly braces have been executed by each individual thread, the team will {\bf join}. This pattern could be repeated over and over again in a single program. This style of parallel processing is known as the {\bf fork-join} model. This makes creating parallel regions extremely simple and, implemented in C, the performance is still better than most. However with increased simplicity the package loses its flexibility and expressiveness.\cite[p83]{ref14} The non-transparent nature of some of the directives in implicit threading packages create debugging extremely difficult; a situation could arise where the programmer simply doesn't know what is happening inside the parallel region!

So, we want more control? {\bf Explicit} threading is the answer! It enables the programmer to control all aspects of the threads they intend to create. From creating a thread, assigning a function to it, synchronising a team, or controlling access to resources. {\it Listing 7} is an example of a explicit threading library, PThreads. It should be immediately apparent that the layout of this code is extremely different to that of the OpenMP example. First the programmer must create a field of type {\bf pthread\_t} this is the threads container (often known as the thread's {\bf handle}) and is used to create the thread, associate it with a function and refer to it in the main context of the program. The actual thread will begin running as soon as it is created by the {\bf pthread\_create()} function. This expects arguments referrring to the handle to initialise, optional thread attributes, the function to be assigned to the thread and any additional arguments in the form of void pointers. Already this is more complex than the implicit thread example yet the level of control the programmer has over threads and what they execute is far greater.  \cite[p89]{ref14} In the {\bf for} loop on line 19 each one of the pthread handles in the {\it threads} array are created and associated to the same function, PrintHello. The only thing that changes is the argument, a void pointer to an integer referencing the identifier of the thread. Unlike OpenMP this is not explicitly defined by the API, in PThreads an identifier exists only if the programmer wishes it to. After this point the team of threads each execute the code inside the PrintHello function and are destroyed by the {\it pthread\_exit()} function. 

The obvious trade-off for increased flexibility is the increased complexity of the code. Also, a big difference to note between both models is the range of functionalities offered. You may notice that unlike the implicit example, there is no facility in explicit threading libraries to simply {\it create} a parallel region. Functions are assigned, parameters are passed, in this maelstrom of handles, threads, parallel regions and functions how is everything synchronised? How can everything possibly run smoothly? 
%delegation and inheritance. OOP vs. Sequential. 
\begin{lstlisting}[language=C, caption={Hello World from PThreads}]
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#define NUM_THREADS	4

void *PrintHello(void *threadid)
{
   long tid;
   tid = (long)threadid;
   printf("Hello World from pthread %ld\n", tid);
   pthread_exit(NULL);
}

int main(int argc, char *argv[])
{
   pthread_t threads[NUM_THREADS];
   long t;
   for(t=0;t<NUM_THREADS;t++)
   {
     pthread_create(&threads[t], NULL, PrintHello, (void *)t);
   }
   
   pthread_exit(NULL);
}
\end{lstlisting}
\begin{figure}
\begin{verbatim}
Hello World from pthread 0
Hello World from pthread 1
Hello World from pthread 2
Hello World from pthread 3
\end{verbatim}
\end{figure}
\subsubsection{Synchronisation}
The art of coordinating simultaneous threads of execution. At its simplest this involves the main thread of an application waiting for executing threads to finish before it can proceed. This practice is known as a {\bf join} function. It can be seen as the opposite of a {\bf fork} operation. If fork creates a team of threads then join brings them back together. This is extremely useful if, at any step during the execution, there is a section of the parallel algorithm that requires a task to have been completed, or a task that only needs to be done once; a bottleneck or a sequential region. The concept of a {\bf barrier} also exists and is like a join inside a parallel region, except the threads aren't terminated when the team is synchronised. At a barrier each thread that encounters it waits until all the threads in the team arrive. Upon arrival of the last thread, all threads are released and continue execution. \cite[p265]{ref14}

The other most basic type of synchronisation is when a thread demands use of a shared resource. It would create havoc if every active thread could access any given shared resource at any time. A simple example highlights one of the effects of not protecting a shared resource from simultaneous use, consider a function that increments a shared resource by 1.
\begin{figure}[h]
\caption{A Race Condition}
\centering
\begin{tabular}{|c|c|c|}
\hline Thread 1 & Thread 2 & Memory Val \\ 
\hline
\hline Read &  & 0 \\ 
\hline  & Read & 0 \\ 
\hline Increment &  & 0 \\ 
\hline  & Increment & 0 \\ 
\hline Write &  & 1 \\ 
\hline  & Write & 1 \\ 
\hline 
\end{tabular} 
\end{figure}
Both threads have access to the shared resource and even though the function may be called twice the result is only written back as 1. This is called a {\bf race condition}, as in there is a race to use the resource. The correct solution is for Thread 1 to obtain a {\bf lock} on the resource which will keep other threads from executing code until the lock is released. This process is known as using mutual exclusion, or a {\bf mutex}.\cite[p272]{ref14} There is scope for other synchronisation directives to work in this place. In the implementation section I will introduce the concept of a {\bf single} directive for use in OpenMP. This protects a group of statements from access by multiple threads by only allowing the first thread to reach the block to execute the instructions.
A race condition can occur anywhere one thread reads from a location that is also being written to by another thread. By using mutual exclusion the programmer can control access to a function so that only one thread can be executing the code at any one time. \cite[p18]{ref14}

Consider the scenario of copying the ghost cells or swapping the pointers in the Game of Life algorithm. If these tasks are not synchronised what happens?
%explain join
%join = barrier?
\subsubsection{Getting into Trouble and the Game of Life}
There are specific points in the Game of Life parallel code that require thread synchronisation to ensure the correctness of the result. Referring to {\it figure 9} there are two synchronisation points. The threads must all {\bf fork} after the ghost cells have been correctly copied and {\bf join} before the grid pointers are swapped and the main game loop iterates. Throughout the code this effect will be achieved in different ways and discussed at length in terms of the differences and solutions for each individual implementations

What would happen if we neglected to synchronise? Well, different things. Firstly both the copying of the ghost cells and the swapping of the pointers should only occur once per cycle. Secondly, these activities are essentially writing to the contents of the array whilst the other threads are waiting to read from it. Without synchronising the threads a {\bf race condition could} occur. The outcome of the read value can never be guaranteed without using synchronisation. In the Game of Life parallel algorithm, this is achieved by using {\bf barrier} objects to alter the flow of control in the algorithm it is explained in-depth in the OpenMP implementation.

Another possible consequence of not synchronising is the {\bf consumer-producer} problem. However, during the design stage of the Game of Life parallel algorithm this outcome was made impossible by the choice of data structure and a coarse-grained processing approach. Nevertheless I have created an example that will explain the problem in more depth using a dynamic work allocation algorithm. \cite[p10]{ref13} This is explained in the appendices A.17.
\smallskip
\begin{mdframed}
{\bf Note Box: } The Dynamic allocation technique could be described as fine-grained. As the size of an individual datum that could be mapped to a computational unit is the smallest possible. One cell. As discussed earlier, the flexibility of the algorithm has increased. Also, this implementation would make a great starting point to implement a work stealing version of the algorithm. However, the algorithm now has more significant overheads involved with scheduling and synchronising the work. Is it worth it?
\end{mdframed}
\smallskip
The downside of using synchronisation objects is the overheads created by their use. Extra memory space allocated for locks, extra functions calls for use and destruction, extra time acquiring and releasing locks. Not only that but if implemented incorrectly they can cause blocks and locks of their own. \cite[Granularity]{ref15}
\section{Implementation}
The languages I'm going to look at have been picked to highlight the fundamental differences in parallel design and threading library functionality and facilities. 
\begin{itemize}
\item {\bf OpenMP} - A mixture of an implicit threading package with an extremely fast and efficient language that also houses an {\bf optimising compiler}.
\item {\bf Java} - An Object-Oriented language and a threading package that supports explicit threading via the inheritance and implementation of a thread class.
\item {\bf C++ 11} - A relatively new addition to the C++ standard library. It is an explicit threading model that supports threading by function delegation.
\item {\bf C++ Boost} - The original alternative to using PThreads in C++. This explicit threading solution will be different from the C++11 implementation by the use of a thread class system similar to Java.
\item {\bf Go} - A recently released language that is created to perform the functions of a systems language only with a more flexible type system. The system of creating parallel code is also extremely different from anything encountered in other models by the use of {\bf Goroutines}.
\end{itemize}
\bigskip
As well as these 5 implementations I have included a Python implementation. This language is {\bf dynamically typed}, {\bf interpreted}, and supports a wide-range of programming styles. In particular interest to me, was the support for functional style {\bf list comprehensions}. These are powerful constructs which are unique in their likeness to {\bf set-builder notation} in {\bf set theory}. One property of the functional program paradigm is that they can be proven mathematically. My idea being that if I can create an implementation in Python using set-builder notation and then list comprehension I can circumvent the process of verification of parallel algorithms or formal proofs. Two subjects which have enough content for an entire project each.
%\subitem class diagram for OOP models
%\item Validation technique

\subsection{C with OpenMP}
This is the obvious first choice for parallel implementation as the design of the parallel algorithm was based around the sequential prototype which was produced in C. Being such a flexible and low-level systems language it gave me an opportunity to look into some features that just aren't present in more modern languages. These are talked about in the next subsection.

C allows the use of preprocessor macro statements. At the top of the file is a list of 10 or so items which represent the settings for the {\bf conditional compilation} of the code({\it listing 8}). This is not only good practice, as it makes any changeable settings very visible to the programmer, it also makes the object file smaller and useless code that may be spent dissecting command line arguments is not present. 
\begin{lstlisting}[language=C, caption={OpenMP program settings in file}]
#define MAXGEN 10000       //the number of generations to compite
#define DIM 512            //the dimension of the grid 
#define LIFE 3             //probability of life, only used if no file read
#define BOOL 1             //use bool for the data type of the arrays, else int
#define SEED 2012          //seed for random algorithm, only used if no file read
#define THREADS 4          //number of threads to allocate
#define SHARED 1           //use shared memory or private memory for threads
#define INLINE 1           //use inline function prototypes
#define REGISTER 1         //use register keyword for global array definition
#define FILENAME "512.dat" //the filename to read in
\end{lstlisting}
These settings are then used to conditionally declare the function prototypes and global variables for the program shown in A.2 - lines 45-72. In the same way, conditional compilation is used to create the correct data structure for the global state arrays shown in A.2 - lines 98 - 116.

The structure and scope of the global state arrays is worth noting. Whilst the variable for these arrays is in the global scope, all of the code that accesses them does so through a pair of copied pointers; {\bf new\_grid\_ptr}, and {\bf grid\_ptr}. Defined in A.2 - lines 78 - 82 and used in A.2 - lines 119, 120. This is to simplify the process of swapping the grids over after the processing of a generation, see {\it figure 9} for reference. Then A.2 - line 125 performs a call to the readFile() function. It can be seen in A.2 - lines 396 - 439. 

A.2 - line 131, declares the private integers for the OpenMP {\bf parallel region}; {\bf start}, {\bf stop} and {\bf tid}. This is the static work allocation calculation algorithm, shown in {\it listing 9} lines 17 and 18. It should be noted that this is based off the pseudo-code algorithm in {\it listing 5}. However the real line of interest is line 11. This is the OpenMP pragrma directive which will direct the compiler to create a team of threads. There are two constructs which are applicable to this problem; {\bf omp parallel} and {\bf omp for}. The construct simply creates a team of threads with parameters defined by the list of {\bf clauses} outlined by the programmer. Clauses help the programmer gain a bit of control over how the OpenMP API manages the implicit threads. Used in this example I am defining some {\bf shared} and {\bf private} variables for each thread. The shared clause means each thread has access to the listed value in shared memory space. In this case the {\bf grid\_ptr}, {\bf new\_grid\_ptr}, {\bf temp\_ptr}, and the number of threads. The private clause means that each thread has its own {\bf local} copy of the variable listed. The {\bf gen} variable is used as a loop counter, the {\bf tid} variable is the thread's identifer, the {\bf start} and {\bf stop} variables define the limits of the static work allocation. After the {\bf \#pragma omp parallel} directive every statement inside the {\bf parallel region}, defined by the curly braces, is executed by each thread in parallel. 
\begin{lstlisting}[language=C, caption={OpenMP directive use and thread creation}]
//......

/*private OMP vars */
int start, stop, tid;

/**
 * Create a team of threads (defined by nthreads) to work on the following code.
 * Run for MAXGEN iterations of Game.
 **/
#if SHARED == 1
#pragma omp parallel shared(grid_ptr, new_grid_ptr, temp_ptr, nthreads) private(gen, tid, start, stop)  num_threads(nthreads)
{
	/*assign the thread an identifier*/
    tid = omp_get_thread_num ();

    /*define the amount of work for each thread */
    start = ((DIM / nthreads) * tid) + 1;
    stop = (DIM / nthreads) + start - 1;
    //....
\end{lstlisting}
The {\bf for} construct differs from {\bf parallel} by also implicitly managing the scheduling of the work. Defined as a {\bf work-sharing} construct, this could replace the use of the parallel region by being placed directly before the main game for loop and it would implicitly share the loop iterations between the created threads. Replacing the need for any for static work allocation to take place. However, in practice this was not so, I could never guarantee the correctness of the results. A symptom of implicit threading is that they are notoriously hard to debug. Therefore I opted for the construct that gave me the most control: parallel. {\it Listing 10} shows the main game loop which is {\bf inside} the parallel region defined by the OpenMP directive. 
\begin{lstlisting}[language=C, caption={OpenMP Game of Life main game loop}]
//...
for (gen = 0; gen < MAXGEN; gen++)
{
    #pragma omp single
    {
        copyGhostCells(grid_ptr);
    }
            
    process (grid_ptr, new_grid_ptr, start, stop, tid);

    #pragma omp barrier
            
    #pragma omp single
    {
        temp_ptr = grid_ptr;
        grid_ptr = new_grid_ptr;
        new_grid_ptr = temp_ptr;
    }
}
\end{lstlisting}
On line 4 the {\bf single} directive means that the first thread to reach the block will execute the statements inside and it will only happen once. There is an implied {\bf barrier} at the end of the block which requires all the other threads to gather there. This allows the completion of the {\bf copyGhostCells} function before the team moves on. Line 9 is the main game function {\bf process()} this is seen in {\it listing 11}. The similarities between this version and the sequential version in {\it listing 4} should be visible with the exception of the conditional statement in the for loop on line 5. This is the last factor in ensuring the threads only process the work that was allocated to them. Each thread will read from the array pointed to by the {\bf grid\_ptr} and write to the array pointed to by the {\bf new\_grid\_ptr}. This ensures that the algorithm will not have to use locks or synchronisation to control the write/read operations on these data structures.
\begin{lstlisting}[language=C, caption={OpenMP Process chunk and calculate moore-neighbourhood}]
inline void process (bool ** grid_ptr, bool ** new_grid_ptr, int start, int stop, int tid)
{
  int i, j, count;

    for (i = start; i <= stop; i++)
    {
        for (j = 1; j <= DIM; j++)
        {
            count =
            grid_ptr[i - 1][j - 1] + grid_ptr[i - 1][j] +
            grid_ptr[i - 1][j + 1] + grid_ptr[i][j - 1] +
            grid_ptr[i][j + 1] + grid_ptr[i + 1][j - 1] +
            grid_ptr[i + 1][j] + grid_ptr[i + 1][j + 1];

            if (count == 3)
            {
                new_grid_ptr[i][j] = 1;
            }
            else if (count < 2 || count > 3)
            {
                new_grid_ptr[i][j] = 0;
            }
            else if (count == 2)
            {
                new_grid_ptr[i][j] = grid_ptr[i][j];
            }
        }
    }
\end{lstlisting}
The barrier in {\it listing 10} on line 11 ensures that all threads gather at this point before they can be released. This means each thread will have finished processing their respective chunks and the pointers can be swapped to allow the generation to complete. If the synchronisation clause was not here then the program runs the risk of swapping the pointers before the process of the global state has completed. A {\bf race condition} would occur and a thread still in the processing phase would write to the wrong location. The final OpenMP directive is another single block. The first thread to reach this block is responsible for swapping the pointers and it will only happen once. The threads gather at the implied barrier and the iteration continues to the next generation.
\begin{figure}
\begin{mdframed}
{\bf Extension box: } I have also implemented a version of the Game of Life using thread {\bf local memory} as opposed to {\bf shared memory}. In this version, after the static work allocation algorithm, each thread is allocated a grid which is stored in its local memory space. This grid is the exact size of the chunk that it needs to process and the chunk from the global state is copied into this local memory array. The idea being that this could be implemented on a distributed parallel processing architecture. Using separate CPUs that only communicate to unzip or zip up the global state arrays. However, the code on a multi-core platform, performs slower than the shared memory version which is not surprising. I feel that it is a brilliant example of {\bf coarse-grained} versus {\bf fine-grained} data structures and whilst I will not talk about it directly in the report my code is in the appendices A.2 lines 175 - 224, lines 375 - 394.
\end{mdframed}
\end{figure}
\subsubsection{Optimising Compiler Features}
What exactly {\bf is} an optimising compiler? C, C++, and Go have forms of optimising compilers. All based around {\bf GCC}, the GNU C Compiler. In a very general sense an optimising compiler will sacrifice compile time and the size of the produced object code for increased runtime speed. GCC in particular has 3 levels of optimisation. Some optimisations can be implemented by the programmer such as {\bf function inlining}. The {\bf inline} keyword is put in front of a function prototype and instructs the compiler to replace every call to that function with the actual code. Increasing the size of the object file but reducing the overheads associated with calling the function, returning arguments or any branching that may take place as code is kept local. Another common optimisation occurs in loops. {\bf Loop invariant code removal}, where the compiler will identify statements inside a loop that may be evaluated on each iteration but may not actually change. The evaluation statement is then moved outside the loop to save on processing. {\bf Loop unrolling} is similar to function inlining where multiple occurrences of the loop's code is placed in series if the loop is known to iterate for a certain number of times. This reduces the amount of times a condition will have to be checked and also how many times a {\bf goto} or {\bf jump} statement is used in the object code.
\subsection{Application of Amdahl's Law}
Unique to the C version is that I have also produced a sequential version to act as a comparison. Linking back to section 4.2.2, I conducted run-time profiling of the sequential code to attempt to attain a figure for the portion of code that is improvable by parallelisation. A quick reminder:\\
\smallskip
\centerline{$ S(N) = \frac{1}{(1-P) + \frac{P}{N}} $}

A more in-depth discussion is available in section 4.2.2 and the output of GProf is available in Appendix A.9. Looking at the flat profile and the call graph, I'm assuming a value for {\bf P} to be 0.991 + 0.9932 / 2 = 0.9921. This is due to the two values reported by GProf for the percentage time spent inside the {\bf process()} function. I am using this figure because during the parallel code it is the {\bf process()} function that is made {\bf concurrent} and {\bf independent}.

The value assumed for {\bf P} means that roughly 99\% of the code inside the sequential version of the Game of Life is eligible for improvement. There is however the concern of increasing the {\bf problem size} which happens as the parallel code is produced. This is due to the need for work scheduling and thread synchronisation. This is not taken into account whilst calculating the speed-up as I have no data to suggest its affect. The addition of these tasks will decrease the value of {\bf P} as the added code for synchronisation and work scheduling cannot be made parallel. {\it Figure 11} shows a graphical representation of the calculation of Amdahl's Law, {\it Figure 12.a} shows the raw data. It can be used for comparison by {\it figure 12.b} test data produced by the Game of Life parallel algorithm written in OpenMP.
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{Amdahl.png}
\caption{A Graph showing the calculated speed up by application of Amdahl's Law}
\label{fig: AmdahlGraph}
\end{figure}
\subsubsection{Testing against Amdahl's Law}
A full table of results is available in the appendices A.10 - A13 and will be explained during the analysis portion of the report. For now I have included data which attempts to stimulate a discussion about the correctness of Amdahl's law. The settings for the results listed in {\it figure 12} were as follows: dimension, 1024, generations, 10000, using shared memory threads, and optimisation level 3. The greatest number of truly parallel tasks my system is capable of running is four. One thread on each core. Considering this, the results are quite promising. {\it Figure 12.b} shows that a sequential run of the program took nearly 40 seconds to execute. Another run of the code using 2 threads showed a speed up of 1.94 which is very close to the maximum calculated speed up of 1.98 seen in {\it figure 12.a}. This means that the estimation for {\bf P}, the proportion of code which can be made parallel, can not have been too far off! Looking at the next run with 4 cores the result is not as pleasing with a speed up of 3.03 compared to a calculated speed up of 3.9. Still it is in line with predictions. Alas, my system does not have enough independent computational units to allow any more meaningful results to be processed and 8 threads and above the performance gets gradually worse. This is not surprising as there are significant overheads related to switching a threads state from running to blocked.

The maximum speed up theoretically possibly from a program where roughly 99\% of the code could be eligible for parallelism is around 126 times faster than a single threaded implementation. This is evidenced by {\it figures 11} and {\it 12} unfortunately I do not have access to a system with 65536 independent cores to test this prediction.

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Speedup.png}
\caption{The Speed up by application of Amdahl's Law}
\label{fig: speedup}
\end{subfigure}
~ 
\begin{subfigure}[b]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{measured.png}
\caption{The measured speed up}
\label{fig: measured}
\end{subfigure}
\caption{Tables representing calculated and measured speed up}
\end{figure}
\subsection{Java with Threads}
Java is one of the most popular languages on the planet. It's simple object-oriented design patterns and extreme portability make it the language of choice for any type of project. The implementation of the Game of Life in this language is inherently, very different to that of a procedural language such as C. The implementation I have produced has three classes. A {\bf Grid} class which houses all of the functionality for creating, reading from, and writing to the global state arrays which are also stored within its structure. The global state arrays, in line with my research located in Appendices A.15, A.16, are created as Java primitive arrays of type boolean. Next a class called {\bf LifeThread} provides the functionality for actually processing the global state arrays and advancing the game to the next generation. The final class is called {\bf GoL}, this class is the controller and creates instances of the other classes and houses the main game loop. The code is available in full in the appendices A.6.

Java supports explicit threading through the use of a Thread class which is provided by the Java library. Any class that wants to exploit all the abilities of a thread will have to implement or inherit the functionality of the Thread class and then ensure that an implementation is provided for a {\bf run()}  method. This method is executed by the calling class and the thread will cease to exist once run() returns. This is where the differences begin, in {\it listing 12} the main game loop is shown. There is no concept of a parallel region like in OpenMP. The main thread has to create new LifeThread objects for every single generation. Lines 9 - 10 show the application of the static work allocation algorithm. After this lines 11 and 12 show the initialisation and creation of LifeThread objects which are then stored in a vector of type LifeThread. Think of this vector as a common {\bf thread pool}. After the threads are all created and references stored inside the vector, the for loop on lines 15 - 17 runs {\bf start()} on each object. The start method implicitly calls the method {\bf run()}. Then run will call processChunk() which houses the code for processing the global state arrays. A similar loop from lines 20 - 21 will now call {\bf join()} on all the threads in the vector. This means that the calling thread will have to wait until all the threads it asked to join have returned from their run methods. This synchronisation is the only type needed in the Java example and makes the code look far simpler than that of the OpenMP implementation. 
\begin{figure}
\begin{lstlisting}[language=Java, caption={Class GoL main game loop in GoL.java}]
//...
Grid g1 = new Grid(DIM, LIFE, FILENAME);
Vector<LifeThread> life_vec = new Vector<LifeThread>();

for(int gen = 0; gen < GEN; gen++)
{
    for(int x = 0; x < THREADS; x++)
    {
        int start = ((DIM / THREADS) * x) + 1;
        int stop = (DIM / THREADS) + start - 1;
        LifeThread life = new LifeThread(x, start, stop, g1, DIM);
        life_vec.add(x, life);
    }

    for(int x = 0; x < THREADS; x++)
    {
        life_vec.get(x).start();
    }   

    for(int x = 0; x < THREADS; x++)
        life_vec.get(x).join();
    
    g1.finishGen();
  
}
//...
\end{lstlisting}
\end{figure}
This is also due to the positioning of the threaded section. Because it is inside the game loop the main thread deals with copying the ghost cells and swapping the pointers via a call to the Grid method {\bf finishGen()} shown on line 23.
%Use appendix A from The Art of Multiprocessor Programming.

%\item gcj and javac
%\item fork, join, yield, sleep
%\item Overheads? Thread creation - compare to C
%\item OOP? Threads as an object?
\subsection{C++}
The implementations presented in this section use two different libraries and two different design methods. Similar to the Java implementation, I have made use of object-orientation in C++. Both versions utilise a class called {\bf Grid}. This class provides basic functionality for the storing, and management of the global state arrays. It is created inside the main function for both the Boost and C++11 implementations.

The Boost version makes more use of object-orientation than the C++11 version. With a program structure very similar to that of Java. A threadClass object is created and then the programmer calls run when they want processing to commence. The C++11 version simply has a function declared in a file that also contains main, this function is then mapped onto the thread using an analogous thread constructor statement. There are two important reasons I have made two very different program structures under the same language. Firstly to highlight that encapsulating the state and behaviour of a thread is a good design paradigm. Secondly to attempt to define what, if any, performance overheads are created by using a version that has a plethora of objects and one that has only 1. 
\subsubsection{Boost}
The implementation really begins with the {\bf Thread.cpp} file. {\bf Listing} 13 is a look inside the {\bf ThreadClass} class and should look similar to the Java Thread class seen in Appendix A.6. The C++ Boost implementation can be found, in full, in the appendix A.4 and the Grid class A.5.
\begin{lstlisting}[language=c++, caption={Boost implementation Thread class methods}]
void ThreadClass::threadMain()
{
  try
  {
    processChunk();
  }
  catch (boost::thread_interrupted& interruption)
  {}
  catch (std::exception& e)
  {}

}

void ThreadClass::run()
{
	internalThread_ = boost::thread(&ThreadClass::threadMain, this);
}

void ThreadClass::join()
{
    internalThread_.join();
}
\end{lstlisting}
The big difference is the inclusion of exceptions. This is not supported in PThreads or OpenMP for C. This is also the first time I have used explicit threading with function delegation. This is different from both the paradigms seen so far. In OpenMP I defined a {\bf parallel region}, in Java I created a class that {\bf inherited} thread functionality. In PThreads, Boost, and C++11 threads, the creation of a thread depends on the address of an expected parameter, a callable function. In this case the {\bf threadMain()} function is passed to the boost::thread() constructor on line 16, this returns a {\bf handle} of the created thread stored in the {\bf \_internalThread} variable. As soon as this is done the thread begins execution. The threadMain function then calls the {\bf processChunk()} function seen on line 4, which uses a pointer to the Grid class to being processing the relevant cells of the global state. This can be seen in A.4 lines 88 - 113.

It should also be noted that the {\bf main()} function for this code is extremely similar to that of the Java implementation. Performing the operations in the same manner in very similar syntax. 
\subsubsection{C++ 11 Threads}
C++11, named due to the release being approved in 2011, is unique in that it is the first time the C++ standard library has included support for threads. The newly incorporated {\bf std::thread} class provides functionality for all the standard array of creation, management, and synchronisation for threads. Even as similar as this method may be to the older Boost library, I have chosen to use a different program structure. See Appendix A.3 for a full code listing.
\begin{lstlisting}[language=c++, caption={Main game loop from C++ 11 implementation}]
//...    
vector<std::thread> threadPool;
//...
for (int gen = 0; gen < MAXGEN; gen ++)
{
    for(int x = 0; x < THREADS; x++)
    {
        int start = ((DIM / THREADS) * x) + 1;
        int stop = (DIM / THREADS) + start - 1;

        threadPool.push_back(std::thread(processChunkExtern, start, stop, grid));
    }
    
    for (auto &t : threadPool)
    {
        if(t.joinable())
            t.join();
    }
    
    grid->finishGen();
}
\end{lstlisting}
This structure focuses on the explicit delegation of functions to threads. The {\bf ThreadC11.cpp} file only has an {\bf inline void processChunkExtern()} and {\bf int main()}. Some of the contents of main are shown in {\it listing 14}. Line 2 shows the declaration of a vector of type std::thread that acts as the thread pool. This holds the initialised threads. In the same way that Java and Boost allocate then join the threads. C++11 does the work allocation on lines 8 and 9, then creates the threads and pushes them into the vector on line 11. This also starts the threads executing the function given by the first parameter. Along with the first parameter the thread is also give the {\bf start}, {\bf stop}, and {\bf grid} parameters. These are treated as arguments to the processChunkExtern function. The std::thread constructor supports {\bf variadic} parameter passing, in that any number of parameters can be passed. This is different to boost, because the work allocation variables and the grid object reference were stored in the ThreadClass initially so the thread creation only required the passing of a function reference for the thread to begin.
\bigskip
\begin{mdframed}
{\bf Knowledge Box:} Another inclusion as part of the C++11 release was automatic {\bf type inference}. This can be seen in {\it listing 15} line 14 and is indicated by the {\bf auto} keyword. In this line a for each loop is being instantiated with members of the threadPool and each object is assigned to the automatically typed variable {\bf t}. This is an extremely useful feature and simplifies of using somewhat ambiguously typed data structures.
\end{mdframed}
\subsection{Go and Goroutines}
Go is a relatively new language that has aspirations of becoming a new type of systems language, with a unique twist; the type system. Whilst being statically checked it also has many elements that are common to a dynamically checked language. In addition to this its take on concurrency is a very unique. Instead of threads running a single function and then ceasing to exist when the function returns {\bf goroutines} are dispatched with a function and can have {\bf channels} open which represent communication and can be used typed and carry work or messages back and forth. However this is not necessary for this implementation, the code is still extremely interesting. There is far more which I wanted to put in that is just as interesting but unfortunately out of scope. Like the way Go handles loops and variadic function calls. See Appendix A.8 for a full code listing.
\begin{lstlisting}[language=C, caption={Go and Goroutines, Game of Life Main Game Loop}]
//...
var wg sync.WaitGroup
//...
type thread struct{
  Id, St, Sp int
}
//...
for x:=0; x < threads; x++ {
    st := ((dim / threads) * x) + 1
    sp := (dim / threads) + st - 1
    threadPool[x] = &thread{ x, st, sp}
}
//...
for i < gen {
    copyGhostCells()
    for x:= 0; x < threads; x++ {
      wg.Add(1)
      go processGrid(threadPool[x])
    }
    wg.Wait()
    copySlice()
    i++
}  
\end{lstlisting}
Lines 4 - 6 in {\it listing 15} show the creation of a new type, a {\bf strcut}. This struct is one of the basic building blocks of the Go language and is different to every other language implemented in this report. It can define a type that holds fields and can also have behaviour by methods using it as a {\bf receiver}. The closest construct this is comparable to is a {\bf class}, however there is no concept of an object, inheritance, or a type hierarchy. The defined type {\bf thread} has three fields associated with it, {\bf Id}, {\bf St}, and {\bf Sp}. The initial character being a upper-case signifies that the fields are accessible outside of the package. 

Line 2 in shows the creation of a {\bf waitGroup}. A unique concept for the Go language that essentially acts as a way of synchronising goroutines. Its closest semantic match is a {\bf join} operation. When a goroutine is dispatched with a function the {\bf wg.Add(1)} statement is executed which increments a counter. When the goroutine completes a sister function {\bf wg.Done()} is called, this decrements the counter. The main thread of execution will wait at the call {\bf wg.Wait()} until the counter is equal to zero again. A simple but powerful synchronisation mechanism. Line 18 dispatches the goroutines with as many threads that have been created and the chunks are processed.
\smallskip
\begin{mdframed}
{\bf Knowledge Box:} There are currently two compilers available for Go language source code. GCCGO, which has a GCC backend and thus incorporates the optimising features of the C compiler. Or the Go compiler, which has a certain level of optimisation, however this is not mutable by the programmer.
\end{mdframed}

\subsection{Python}
The last implementation of the Game of Life I have produced is written in Python. A very powerful, dynamically typed, interpreted language. The object of this implementation is to utilise the functional programming features of python and produce a version of the game that could be proven. In this case all of the processing is made up of {\bf list comprehensions}, whilst being very concise and simple to understand also have a close relation to {\bf set-builder} notation, a key aspect of set-theory  in mathematics.
\begin{lstlisting}[language=Python,caption={A Python Game of Life using List Comprehensions}]
def initGrid():
    return [[0 for x in range(dim + 2)] for x in range(dim + 2)]
    
def countGrid(x):
    return [[count(x, i, j) for j in range(1, len(x[1]) - 1)]
    for i in range(1, len(x) - 1)]    

def evolve(count_grid, x):
    return [[(change(count_grid, x, i, j)) for j in range(dim + 2)]
    for i in range(dim + 2)]

def count(x, i, j):
    return (x[i - 1][j - 1] + x[i - 1][j] + x[i - 1][j + 1]
     + x[i][j - 1] + x[i][j + 1] + x[i + 1][j - 1] +
     x[i + 1][j] + x[i + 1][j + 1])
     
def change(count_grid, x, i, j):
    if i > 0 and i < dim + 1 and j > 0 and j < dim + 1:
        if count_grid[i - 1][j - 1] == 3 or (count_grid[i - 1][j - 1] == 2 and
        x[i][j] == 1):
            return 1
        elif count_grid[i - 1][j - 1] < 2 or count_grid[i - 1][j - 1] > 3:
            return 0
        elif count_grid[i - 1][j - 1] == 2:
            return x[i][j]
    else:
        return 0     
\end{lstlisting}
{\it Listing 16} shows all of the main processing functions in the Python Game of Life code. 
\begin{enumerate}
\item Firstly {\bf initGrid()}, on line 1,  performs a list comprehension to zero-initialise a grid with the required dimensions.
\item Sequentially, this grid is initialised with data from a *.dat file. Line 21 in A.7.
\item Next, sequentially again, the ghost cells are copied. Line 36 in A.7.
\item Next a {\bf countGrid()} is obtained, line 12, by sending the current global state grid, x, and mapping the function {\bf count()} on to every cell. Returning a grid that has only the global state represented, no border cells. Where each cell in the returned grid is a number representing the calculation of the moore-neighbourhood.
\item Next {\bf evolve()} maps the function {\bf change()} onto the list comprehension it returns. Change takes the count grid, current global state, and coordinates. It applies the transitional function and the returned grid represents the next generation.
\end{enumerate}
None of these functions have side-effects as emphasized by the functional programming style. Also, no function depends on some global state, hence they are all deterministic. This means that those functions always return the same output when called with a specific input. They are a mapping of input to output.

In addition to this the Python version has a GUI that I have implemented using a the Pygame package to output the state of the global state after each generation. This is not talked about here as it is out of scope of my project, however it was extremely useful in giving a visual notion of the correctness of my code and implementations. The full code listing can be found in the appendix A.7.
\section{Analysis}
\subsection{Testing Procedure}
Every language was tested using 1, 2, and 4 threads using either 1024 or 2048 dimensioned grids. The number of generations was either 1000 or 10000. The procedure for producing a result which I deemed ``correct'' was as follows:
\begin{itemize}
\item Build grid of specified size using {\bf buildArray.c} to generate *.dat file the program can be seen in A.19.
\item Run the Python Game of Life, GoL.py, to assertain correct number of ``alive'' cells after X number of iterations.
\end{itemize}
\begin{mdframed}
{\bf A note about the results:} Even though some of the code implementations have preprocessor flags defined for conditional compilation of different global state types or use of malloc or calloc, all of the testing was done using calloc and boolean typed arrays, where appropriate. The Java timing system would only allow output to 3 decimal places whereas Go allowed 4 and C or C++ used the {\bf -lrt}, librealtime library, which allowed 6. The results are all recorded in the raw format received from the timing systems. It should be noted that timing, infact any type of runtime profiling, creates an overhead so this is never going to represent the exact figure for an execution. Different timing packages may have different overheads. This is an area which could warrant investigation however it is out of scope of my investigation.
\end{mdframed}
\subsection{Results}
The full listing of results is available in the appendices A.10 - A.13. A few general trends can be realised by looking at the results:

\begin{itemize}
\item Increasing the size of the grid made the execution time 4 times as long, with the noted exception of Java which fell a little bit below this at 3.91 times slower on a 2048 size grid.
\item Increasing the number of generations increased the execution time by around 8 or 9 times. This is consistent with all the languages. It is contrary to my expectation that a 10 times increase in the number of generations would show at least a 10 times increase in processing time. My prediction is based on the fact that each thread has 10 times the work to do and still has all of the synchronisation associated with threading. I cannot elaborate a theory as to why the measured increase in execution time was 8 - 9 times greater and not 10 or over.
\item Increasing the number of threads at execution decreased the time taken. There is a definite hierarchy in terms of languages which conform to the speed up predictions of Amdahl's Law. {\it figure 13.a}
\end{itemize}

\begin{table}[ht]

\caption{Dimension: 1024, Generations: 1000, Threads: 1\\Global State at 1000 generations is 44790 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java & Go \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 5.718475 & 5.765054	& 4.554163 & 9.463 & 101.2006 \\
2 & 5.677659 & 5.771371 & 4.56045 & 8.913 & 100.5934 \\
3 & 5.722809 & 5.790001	& 4.553645 & 8.908 & 101.1012 \\
4 & 5.721358 & 5.795148 & 4.561694 & 9.112 & 100.9822 \\
5 & 5.716541 & 5.782545 & 4.554886 & 9.024 & 99.5587 \\
Average & 5.7113684 & 5.7808238 & 4.5569676 & 9.084 & 100.68722 \\ [1ex]

\hline %inserts single line

\end{tabular}

\end{table}
\begin{table}[ht]

\caption{Dimension: 1024, Generations: 1000, Threads: 2\\Global State at 1000 generations is 44790 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java & Go \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 3.047201 & 3.114075 & 2.353971 & 4.714 & 74.8022 \\
2 & 3.043579 & 3.116941 & 2.355625 & 4.568 & 72.2883 \\
3 & 3.04981 & 3.127248 & 2.356607 & 4.736 & 71.0558 \\
4 & 3.055256 & 3.118521 & 2.356541 & 4.68 & 75.5541 \\
5 & 3.050681 & 3.130182 & 2.359814 & 4.694 & 70.5531 \\
Average & 3.0493054 & 3.1213934 & 2.3565116 & 4.6784 & 72.8507 \\
Speed Up & 1.8730063574 & 1.8520010326 & 1.933776859 & 1.9416894665 & 1.3821036723 \\ [1ex]


\hline %inserts single line

\end{tabular}

\end{table}
\begin{table}[ht]

\caption{Dimension: 1024, Generations: 1000, Threads: 4\\Global State at 1000 generations is 44790 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java & Go \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 2.200051 & 2.181026 & 1.328827 & 3.867 & 95.5914 \\
2 & 2.144076 & 2.077911 & 1.422537 & 3.881 & 95.0917 \\
3 & 2.092156 & 2.096594 & 1.401127 & 3.94 & 94.5871 \\
4 & 2.083783 & 2.098059 & 1.474601 & 3.879 & 94.9951 \\
5 & 2.087061 & 2.102909 & 1.404484 & 3.881 & 95.2215 \\
Average & 2.1214254 & 2.1112998 & 1.4063152 & 3.8896 & 95.09736 \\
Speed Up & 2.6922315534 & 2.7380402347 & 3.2403600558 & 2.335458659 & 1.058780391 \\ [1ex]


\hline %inserts single line

\end{tabular}
\end{table}

{\it Figure 13.a} shows the measured speed up of the different implementations on a 2048 grid with 1000 generations processed. Also plotted is a line depicting the calculated speed up from the application of Amdahl's Law. This further backs up the calculated value for {\bf P}, the proportion of code that can be improved, as the OpenMP line is so closely related to the that of the calculation. It is worth noting that the calculation of Amdahl's Law is based on a sequential C version. 

C++11, Boost and Java maintain a relatively high speed up after the use of 2 threads, however this falls away after using 4 threads. It is a testament to the high level of scalability and efficiency that C and OpenMP offer. {\bf Figure 13.b} shows a relative comparison of timing over 4 of the implementations. Java is by far the slowest, this is a symptom of the {\bf JIT}/{\bf JRE} environment which the language offers. With increased portability comes decreased performance. Java offers no features for optimisation and whilst it is still a compiled language to some extent, the JIT compiler for the produced bytecode class files lets it down. C++11 and C++ Boost perform very similarly over the entire course of the testing. However close analysis of the results show that C++ 11 maintains a small, albeit constant, advantage. This could be due to the parallel design model I used. Delegation of the function that applies the transitional function removes the overheads associated with object creation that the Boost implementation will suffer from. 

Go, to a large extent, has been left out of the testing process. After initial results proved extremely poor in comparison to the other implementations, this can be seen in {\it tables 1}, {\it 2}, and {\it 3} where performance increases then actually decreases when 1, 2, and 4 threads are used. Go is a language very much in its infancy. The runtime system, rather than creating new threads which act as independent conduits for the execution of processors, maps the goroutines to OS threads. This is done to prevent blocking in certain situations. However, it should be noted that there is temporary functionality included in Go at the current time which allows it to map more goroutines to more OS threads. This function GOMAXPROCS, which can be seen on A.8 line 43, allows the Go runtime scheduler to map more goroutines to OS threads and thus more multi-core processing units. The functionality is going to be short lived as the development team have cited the runtime scheduler as a component that will be changed drastically. 
\begin{figure}[]
\centering
\begin{subfigure}[b]{1.1\textwidth}
\centering
\includegraphics[width=\textwidth]{measuredSpeedup2048.png}
\caption{The Measured Speed Up across all implementations on 2048 size grid}
\label{fig: speedup1}
\end{subfigure}
~ 
\begin{subfigure}[b]{1.1\textwidth}
\centering
\includegraphics[width=\textwidth]{measured204810004.png}
\caption{The Measured Times across all implementations on a 2048 size grid}
\label{fig: measured1}
\end{subfigure}
\centering{
\caption{Graphs showing measured speed up and measured timing of implmentations processing a 2048 grid, 1000 generations}}
\end{figure}
\subsection{Efficiency}
C is a language which, in this situation, cannot be beaten in its extreme processing efficiency. Performing on average 28\% faster than the C++ implementations and, on average 2 to 3 times faster than Java. The difference is even greater when more threads are used as Java doesn't scale nearly as well as C with OpenMP. 

Whilst C was the clear winner here, reaping the benefits of a lightweight type system and the optimising compiler. The Java and C++ versions weren't total disasters, and their performance can be attributed some certain properties:
\begin{itemize}
\item Java is strictly an OOP language. Forcing design decisions that hamper the efficiency. Namely the overheads created by using threads as objects.
\item C++ is also an OOP language, however it does offer other paradigms. C++11 has slightly better performance than C++ Boost. I feel this is due to the lower use of objects in the C++11 program's design. Whereas the slower implementation, using Boost, has a very similar program structure to the even slower Java.
\item The overheads in question refer to the creation, storage, and manipulation of objects that require initialisation upon each iteration of the main game loop.
\end{itemize}
C using OpenMP had no issues like this, threads are created at the start of a parallel region, their instructions and method calls existing in a shared memory space. They are only joined after the end of the main game loop. Removing the overheads that C++ and Java associate with thread creation.
%Java and C++ are Object Oriented languages, the only versions which made significant use of object-oriented design were the C++ Boost and Java implementations. This is mirrored in the results with C++ Boost consistently performing slower, albeit by a small margin, than C++ 11. The C++ 11 function was not a member of any class and was coded in a procedural fashion however the Boost implementation had to create new thread class objects for every iteration. Java's poor performance could be attributed to the object oriented nature or the program. Both the Boost and Java versions were structured so that every iteration the runtime system will have to create and then destroy a team of threads. This will have significant overheads compared to languages like OpenMP where threads are maintained throughout the entirety of the parallel region.
\subsection{Scalability}
Scalability is another area which highlights the immense power of C and OpenMP. Performing just under the calculated speed up defined by Amdahl's Law, {\it figure 13.a}. In reality when moving from 1 thread to 2 threads all the languages performed satisfactorily in terms of speed up as seen in {\it figure 13.b} and the results tables. Both the C++ implementations trailed just behind C with Java bringing up the rear. The difference was only highlighted when moving from 2 threads to 4 threads. Both the Java and C++ implementations could not maintain the expected speed up and lost out to C. 
\bigskip
\begin{mdframed}
{\bf Efficient use of Resources :} It should be noted that, as much as I endeavoured to measure this facet of my implementations and their executions, I could never obtain a figure that I trusted because of the effect of the overheads associated with measuring this property. Due to this no formal notes have been taken on the subject. The only figures I have are observed form watching system monitors and the processor's utilisation graph. C and OpenMP, under all loads and settings consistently used between 95-100\% of the CPU. C++ used around 90\% - 70\% dependant on number of threads invoked. Java was the lowest with around 60\% for all settings. However, these figures are a guide and are only included as a personal observation.
\end{mdframed}
\subsection{Simplicity}
Each language had benefits and pitfalls in this area, thus it is hard to define a whether any particular implementation excelled:
\begin{itemize}
\item {\bf OpenMP} - The use of OMP directives and the mental process involved with creating code inside a parallel region seemed natural and development was quick and easy. Producing the code was simple and fluid, even using the synchronising directives, like {\bf barrier}, and defining code to run sequentially inside a parallel region using directives like {\bf single}. The downsides; implicit threading languages have far less control than explicit ones. The lack of control makes debugging any error extremely difficult. This is due to the nontransparent nature of some of the directives, and in some cases the lack of documentation, in particular it took me a while before I realised there was an implicit barrier at the end of a {\bf single} directive. The {\bf for} directive was a big disappointment in this API. It was touted as a way to implicitly schedule loop iterations to computational cores, however it never produced the correct result when compared with a static work allocation algorithm and indexing.
\item {\bf Java} - Inheriting the functionality from a class and implementing the run method is a simple, straight-forward, well-defined design paradigm. It makes creating a thread, and defining behaviour easy. However, in comparison to a method of function delegation, inheriting from a thread class may seem like overkill and a bit restrictive. Consider the scenario where a programmer simply wants one thread to perform one small, pre-defined function, repetitively. Creating a thread, an object, then calling start, is a very verbose way of doing this. Especially when languages like Go let the programmer simply call the function with the Go keyword infront of it. Programming in this manner does have its benefits, any created thread class's state and behaviour are effectively encapsulated, removing the need for extended knowledge of a system and making the programmers job far easier.
\item {\bf Boost Library}  - Good, detailed documentation and very easy to use, even though it works on a function delegation basis, my particular implementation encapsulated a lot of the threads functionality and made the design similar to that of Java. Even though this paradigm was used the implementation retained its ability to be used in an explicit, function delegation manner.
\item {\bf C++ 11} - Much newer than the Boost library, so naturally there is less documentation available. However, of what there was, it was simple, generic and easy to understand. This is not a ground-breaking library, apart from its ability to simplify threaded C++ code between Windows and Unix, it lacks the uniqueness to set it apart from other implementations. This is not a bad thing, as I got the impression that, ``it just works'' is a core philosophy. The implementation on the other hand did take a bit longer to produce. The method of creating a stand-alone function, that could be passed to a thread creation statement as a function pointer, took longer than expected.
\item {\bf Go} - Whilst extremely disappointing performance-wise, this language was a dream to code in. The dynamic {\it feel} of the language made creating code simple and easy, I didn't have to think to deeply about anything I produced, and the flexibility due to the lack of a type hierarchy made managing the global state data structures easy and fast. If I wanted a function to do something, I could create it, easily, quickly, and it worked. The process of explicit threading and function delegation still applies yet it was possible by just adding the keyword {\bf go} in front of a function call. 
\end{itemize}
\subsection{Portability}
In OpenMP the programmer is constrained by implicit threading and having to use parallel regions. In Java, the programmer is constrained by the thread class inheritance model. In both of these implementations there is no way to simply delegate a function to a thread, nor have the flexibility to chose more than one parallel design structure. The example I produced with C++ Boost and Threads is the most portable algorithm in this situation. It has the ability to create parallel solutions using a class system, where a class can encapsulate the thread and its behaviour, shown in the Boost library implementation. It also has a high level of control and explicit threading facilities, this is shown in the C++ 11 implementation, by the use of simple function declaration that doesn't require the function to be a member of any class. This makes C++ very compatible with parallel solutions that come from any background. It has the flexibility to offer a package that supports a range of parallel programming paradigms.
\section{Conclusion}
I have provided a qualitative and quantitative analysis of the produced implementations. Based on my findings I was hoping to form a conclusion based around the best language or library for a simple parallel problem. However I feel the results offer a more complex answer.

C with OpenMP has proved to be the most efficient, scalable and simple to code in. The unique facility of a parallel region makes producing code easy and fast. However it is not very portable, any algorithm created in this paradigm will suffer from being tied to one implementation. It is also terrible to debug, a symptom of the implicit threading paradigm.

C++ on the other hand offers fast and efficient performance only slightly slower than C, and also a more generic programming interface, with the newly released C++ 11, Boost, and object-oriented design. It truly is a powerful, and portable language.

I was very impressed with Go. It was extremely easy to use, and the flexibility offered by the dynamic features makes creating code very fast and simple. The lack of a type hierarchy made having access to data simple and the creation of a goroutine was easy and concise. It's a shame about the performance and I can only hope that it gets better with newer releases.

The overall answer is, don't use Java for parallel programs. It is restrictive, and verbose, it doesn't scale well, and is slow. For performance, the overheads associated with object-oriented design and the JIT compilation system do not create a useful parallel programming environment. 

%Some sort of choice based on the most appropriate language.
\section*{Reflection}
\begin{itemize}
\item I have learnt a vast amount about creating concurrent components, parallel processing and the languages and libraries required to implement them.
\item  Planning this project has been key to its success. The entire implementation and analysis process was done on an iterative basis. This worked for me as it meant I could be more flexible about the amount of content I produced.
\item I have used Git as a project management tool, details of my use are in the appendices A.18.
\item The project was very ambitious, it could have benefited from a more constrained scope from the outset. I am happy with the result however I think a better analysis could have been achieved if I had chosen to undertake less work.
\item I typeset the entire project using the \LaTeX package and TeXstudio environment. I have learnt a considerable amount using this package and now would not consider producing a document without it.
\end{itemize}
\subsection*{Overcoming Problems}
The implementation and analysis sections will have already outlined most of the major problems I encountered whilst making this project. However there are some more abstract issues that I had that are worth pointing out. 
\begin{itemize}
\item Testing was hard, monotonous work. Shell scripts excel at this sort of work. An example of a testing shell script used is available in appendix A.21
\item The {\bf GDB}, GNU DeBugger, has proved invaluable to any issue I have had with my code. I have also used {\bf Valgrind} and {\bf GProf} to evaluate my code. Details of the use of these tools can be found in the extension investigation in appendix A.16. Use of GProf also helped me estimate a figure for {\bf P} in the context of Amdahl's Law.
\item I had an issue where I could not replicate my results for a few days, it came to my attention after sifting through piles of code that I had forgotten the optimiser flag in the command line call to the compiler.
\end{itemize}


\section*{Extensions and Future Investigations}
Throughout the project I have listed possible further work that could have been conducted through the use of {\bf extension boxes}. There are however a few of these which I am eager to pursue in my own time. Firstly an investigation into the use of a specific array data type and its affect on performance. I conducted preliminary research into this area (appendix A.16), however I feel it could be a very promising area and help to continue my professional development.

Also, listed in appendix A.17, was my research into dynamic work allocation algorithms. This is the obvious next step in extending the parallel algorithm. 

The final area in which I would like to research is distributed systems and how this may perform using a much larger, more powerful, array of computational units. My research into a local memory version of the Game of Life is available in Appendix A.2 lines 175 - 224.

A full code listing, commit logs, and tex files are available on my github page for public access. https://github.com/xp1990/
\pagebreak
\section{Bibliography}
\begin{itemize}
\item The Art of Multiprocessor Programming Herlihy, Maurice. E-Book. Publisher Elsevier Science, 2012.
\item The Art of Concurrency A Thread Monkeyâ€™s Guide to Writing Parallel Applications, Breshears, Clay. E-Book. Publisher O'Reilly Media, 2009.
\item Evolution of Parallel Cellular Mechanics: The Cellular Programming Approach, Moshe, Sipper. Book. Publisher Springer, 1997.
\item Computer Organisation and Design: The Hardware/Software Interface, Patterson, Hennessy. Book. Publisher Morgan Kaufmann, 2009.
\item The Design, of an Optimizing Compiler. Book. Wulf, William et al. Book. Publisher Elsevier Computer Science Library, 1977.
\end{itemize}
\nocite{*}
\bibliographystyle{unsrt}
\bibliography{Project.bib}
\pagebreak
\appendix
\pagebreak
\section{Appendices}
\subsection{Sequential C Implementation}
\lstinputlisting[language=C]{../Sequential/seqGoL.c}
\pagebreak
\subsection{OpenMP C Implementation}
\lstinputlisting[language=C]{../OpenMP/edgol.c}
\pagebreak
\subsection{C++ 11 Implementation}
\lstinputlisting[language=C++]{../C++/ThreadC11.cpp}
\pagebreak
\subsection{C++ Boost Threads Implementation}
\lstinputlisting[language=C++]{../C++/Thread.cpp}
\pagebreak
\subsection{C++ Grid Class Implementation}
\lstinputlisting[language=C++]{../C++/Grid.cpp}
\pagebreak
\subsection{Java Threads Implementation}
\lstinputlisting[language=Java]{../Java/GoL.java}
\pagebreak
\subsection{Python Functional Implementation}
\lstinputlisting[language=Python]{../Pyhton/GoL.py}
\pagebreak
\subsection{Go with Go Routines Implementation}
\lstinputlisting[language=C]{../Go/GoL.go}
\pagebreak
\subsection{Flat Profile and Call-Graph for seqGoL.c using runtime profiler Gprof}
\begingroup
\fontsize{10pt}{8pt}
\begin{verbatim}
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 56.47      1.98     1.98 104857600     0.00     0.00  getCount
 29.95      3.02     1.05 104857600     0.00     0.00  applyRule
 12.90      3.48     0.45      100     4.51    34.76  process
  0.57      3.50     0.02        1    20.06    20.06  fillRand
  0.29      3.51     0.01        2     5.02     5.02  printGrid
  0.00      3.51     0.00      100     0.00     0.00  copyGhostCells
  0.00      3.51     0.00        1     0.00     0.00  init

 %         the percentage of the total running time of the
time       program used by this function.

cumulative a running sum of the number of seconds accounted
 seconds   for by this function and those listed above it.

 self      the number of seconds accounted for by this
seconds    function alone.  This is the major sort for this
           listing.

calls      the number of times this function was invoked, if
           this function is profiled, else blank.
 
 self      the average number of milliseconds spent in this
ms/call    function per call, if this function is profiled,
	   else blank.

 total     the average number of milliseconds spent in this
ms/call    function and its descendents per call, if this 
	   function is profiled, else blank.

name       the name of the function.  This is the minor sort
           for this listing. The index shows the location of
	   the function in the gprof listing. If the index is
	   in parenthesis it shows where it would appear in
	   the gprof listing if it were to be printed.


		     Call graph (explanation follows)
granularity: each sample hit covers 2 byte(s) for 0.29% of 3.51 seconds

index % time    self  children    called     name
                                                 <spontaneous>
[1]    100.0    0.00    3.51                 main [1]
                0.45    3.02     100/100         process [2]
                0.02    0.00       1/1           fillRand [5]
                0.01    0.00       2/2           printGrid [6]
                0.00    0.00     100/100         copyGhostCells [7]
                0.00    0.00       1/1           init [8]
-----------------------------------------------
                0.45    3.02     100/100         main [1]
[2]     99.1    0.45    3.02     100         process [2]
                1.98    0.00 104857600/104857600     getCount [3]
                1.05    0.00 104857600/104857600     applyRule [4]
-----------------------------------------------
                1.98    0.00 104857600/104857600     process [2]
[3]     56.4    1.98    0.00 104857600         getCount [3]
-----------------------------------------------
                1.05    0.00 104857600/104857600     process [2]
[4]     29.9    1.05    0.00 104857600         applyRule [4]
-----------------------------------------------
                0.02    0.00       1/1           main [1]
[5]      0.6    0.02    0.00       1         fillRand [5]
-----------------------------------------------
                0.01    0.00       2/2           main [1]
[6]      0.3    0.01    0.00       2         printGrid [6]
-----------------------------------------------
                0.00    0.00     100/100         main [1]
[7]      0.0    0.00    0.00     100         copyGhostCells [7]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[8]      0.0    0.00    0.00       1         init [8]
-----------------------------------------------

Index by function name

   [4] applyRule               [3] getCount                [2] process
   [7] copyGhostCells          [8] init
   [5] fillRand                [6] printGrid

\end{verbatim}
\endgroup
\subsection*{Test Results}
\subsection{1024 Grid 1000 Generations}
\begin{table}[ht]

\caption{Dimension: 1024, Generations: 1000, Threads: 1\\Global State at 1000 generations is 44790 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java & Go \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 5.718475 & 5.765054	& 4.554163 & 9.463 & 101.2006 \\
2 & 5.677659 & 5.771371 & 4.56045 & 8.913 & 100.5934 \\
3 & 5.722809 & 5.790001	& 4.553645 & 8.908 & 101.1012 \\
4 & 5.721358 & 5.795148 & 4.561694 & 9.112 & 100.9822 \\
5 & 5.716541 & 5.782545 & 4.554886 & 9.024 & 99.5587 \\
Average & 5.7113684 & 5.7808238 & 4.5569676 & 9.084 & 100.68722 \\ [1ex]

\hline %inserts single line

\end{tabular}

\end{table}
\begin{table}[ht]

\caption{Dimension: 1024, Generations: 1000, Threads: 2\\Global State at 1000 generations is 44790 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java & Go \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 3.047201 & 3.114075 & 2.353971 & 4.714 & 74.8022 \\
2 & 3.043579 & 3.116941 & 2.355625 & 4.568 & 72.2883 \\
3 & 3.04981 & 3.127248 & 2.356607 & 4.736 & 71.0558 \\
4 & 3.055256 & 3.118521 & 2.356541 & 4.68 & 75.5541 \\
5 & 3.050681 & 3.130182 & 2.359814 & 4.694 & 70.5531 \\
Average & 3.0493054 & 3.1213934 & 2.3565116 & 4.6784 & 72.8507 \\
Speed Up & 1.8730063574 & 1.8520010326 & 1.933776859 & 1.9416894665 & 1.3821036723 \\ [1ex]


\hline %inserts single line

\end{tabular}

\end{table}
\begin{table}[ht]

\caption{Dimension: 1024, Generations: 1000, Threads: 4\\Global State at 1000 generations is 44790 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java & Go \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 2.200051 & 2.181026 & 1.328827 & 3.867 & 95.5914 \\
2 & 2.144076 & 2.077911 & 1.422537 & 3.881 & 95.0917 \\
3 & 2.092156 & 2.096594 & 1.401127 & 3.94 & 94.5871 \\
4 & 2.083783 & 2.098059 & 1.474601 & 3.879 & 94.9951 \\
5 & 2.087061 & 2.102909 & 1.404484 & 3.881 & 95.2215 \\
Average & 2.1214254 & 2.1112998 & 1.4063152 & 3.8896 & 95.09736 \\
Speed Up & 2.6922315534 & 2.7380402347 & 3.2403600558 & 2.335458659 & 1.058780391 \\ [1ex]


\hline %inserts single line

\end{tabular}
\end{table}
\pagebreak
\subsection{2048 Grid 1000 Generations}
\begin{table}[ht]

\caption{Dimension: 2048, Generations: 1000, Threads: 1\\Global State at 1000 generations is 180192 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 23.64823 & 23.755266 & 18.468408 & 35.117 \\
2 & 23.64879 & 23.754745 & 18.424642 & 35.209 \\
3 & 23.606505 & 23.773273 & 18.425841 & 35.025 \\
4 & 23.596945 & 23.764332 & 18.465193 & 34.991 \\
5 & 23.583807 & 23.810464 & 18.433137 & 35.67 \\
Average & 23.6168554 & 23.771616 & 18.4434442 & 35.2024 \\ [1ex]



\hline %inserts single line

\end{tabular}
\end{table}
\begin{table}[ht]

\caption{Dimension: 2048, Generations: 1000, Threads: 2\\Global State at 1000 generations is 180192 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 13.73039 & 14.013883 & 9.371935 & 19.719 \\
2 & 13.740023 & 13.911092 & 9.384064 & 19.802 \\
3 & 13.720766 & 13.941342 & 9.370194 & 19.8 \\
4 & 13.777311 & 13.958943 & 9.400541 & 20.005 \\
5 & 13.769952 & 13.915513 & 9.40014 & 19.719 \\
Average & 13.7476884 & 13.9481546 & 9.3853748 & 19.809 \\
Speed Up & 1.7178782871 & 1.7042839488 & 1.9651260171 & 1.7770912212 \\ [1ex]




\hline %inserts single line

\end{tabular}
\end{table}
\begin{table}[ht]

\caption{Dimension: 2048, Generations: 1000, Threads: 4\\Global State at 1000 generations is 180192 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 9.008888 & 9.105704 & 4.911145 & 14.523 \\
2 & 9.032154 & 9.097899 & 4.939797 & 14.128 \\
3 & 8.9769 & 9.149642 & 4.923635 & 14.254 \\
4 & 9.058067 & 9.122737 & 4.927098 & 14.851 \\
5 & 9.065694 & 9.093698 & 4.972541 & 14.787 \\
Average & 9.0283406 & 9.113936 & 4.9348432 & 14.5086 \\
Speed Up & 2.6158578244 & 2.6082711136 & 3.7373921425 & 2.4263126697 \\ [1ex]

\hline %inserts single line

\end{tabular}
\end{table}
\pagebreak
\subsection{2048 Grid 10000 Generations}
\begin{table}[ht]

\caption{Dimension: 2048, Generations: 10000, Threads: 1\\Global State at 10000 generations is 122390 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 212.285539 & 213.090033 & 161.289775 & 304.367 \\
2 & 212.501207 & 213.985421 & 160.55621 & 303.586 \\
3 & 215.461257 & 212.588975 & 161.308851 & 303.005 \\
4 & 211.985123 & 213.58421 & 161.95621 & 304.221 \\
5 & 213.216551 & 213.005482 & 161.230515 & 305.01 \\
Average & 213.0899354 & 213.2508242 & 161.2683122 & 304.0378 \\ [1ex]


\hline %inserts single line

\end{tabular}
\end{table}
\begin{table}[ht]

\caption{Dimension: 2048, Generations: 10000, Threads: 2\\Global State at 10000 generations is 122390 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 125.401229 & 124.866112 & 81.70924 & 171.885 \\
2 & 125.984215 & 124.256661 & 81.965258 & 171.52 \\
3 & 124.65489 & 124.556122 & 81.755491 & 171.012 \\
4 & 125.115211 & 124.998012 & 81.5522 & 172.869 \\
5 & 126.001258 & 125.604193 & 81.659599 & 172.55 \\
Average & 125.4313606 & 124.85622 & 81.7283576 & 171.9672 \\
Speed Up & 1.6988569237 & 1.7079711704 & 1.9732234556 & 1.7679987812 \\ [1ex]

\hline %inserts single line

\end{tabular}
\end{table}
\begin{table}[ht]
\caption{Dimension: 2048, Generations: 10000, Threads: 4\\Global State at 10000 generations is 122390 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 87.780913 & 91.313563 & 47.28809 & 128.485 \\
2 & 87.52839 & 87.500966 & 47.25991 & 129.021 \\
3 & 87.125621 & 88.005461 & 47.300156 & 128.226 \\
4 & 87.432156 & 88.215621 & 48.364031 & 128.777 \\
5 & 87.001245 & 88.584513 & 47.276924 & 127.01 \\
Average & 87.373665 & 88.7240248 & 47.4978222 & 128.3038 \\
Speed Up & 2.4388348068 & 2.4035296492 & 3.3952780302 & 2.3696710464 \\ [1ex]


\hline %inserts single line
\end{tabular}
\end{table}
\pagebreak
\subsection{1024 Grid 10000 Generations}
\begin{table}[ht]
\caption{Dimension: 1024, Generations: 10000, Threads: 1\\Global State at 10000 generations is 30453 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 50.549696 & 50.683087 & 39.683063 & 73.924 \\ 
2 & 50.544642 & 50.640006 & 39.692904 & 74.112 \\
3 & 50.502221 & 50.660579 & 39.542203 & 76.558 \\
4 & 50.498303 & 50.816993 & 39.741123 & 75.056 \\
5 & 50.701188 & 50.705343 & 39.693974 & 76.727 \\
Average & 50.55921 & 50.7012016 & 39.6706534 & 75.2754 \\ [1ex]



\hline %inserts single line
\end{tabular}
\end{table}
\begin{table}[ht]
\caption{Dimension: 1024, Generations: 10000, Threads: 2\\Global State at 10000 generations is 30453 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 26.977912 & 27.354263 & 20.350234 & 39.417 \\
2 & 26.931985 & 27.326674 & 20.12551 & 39.226 \\
3 & 27.142364 & 27.329037 & 20.259776 & 39.73 \\
4 & 27.037353 & 27.352157 & 20.381583 & 39.509 \\
5 & 27.172559 & 27.473758 & 20.356006 & 39.73 \\
Average & 27.0524346 & 27.3671778 & 20.2946218 & 39.5224 \\
Speed Up & 1.8689338223 & 1.8526280631 & 1.9547372595 & 1.9046262373 \\ [1ex]




\hline %inserts single line
\end{tabular}
\end{table}
\begin{table}[ht]
\caption{Dimension: 1024, Generations: 10000, Threads: 4\\Global State at 10000 generations is 30453 alive cells} % title of Table

\centering % used for centering table

\begin{tabular}{c c c c c} % centered columns (4 columns)

\hline\hline %inserts double horizontal lines

Test & C++ 11 & C++ Boost & C OpenMP & Java \\ [0.5ex] % inserts table 

%heading

\hline % inserts single horizontal line

1 & 16.985359 & 17.143739 & 10.534883 & 27.501 \\
2 & 16.981238 & 17.15225 & 10.602769 & 27.604 \\
3 & 16.990126 & 17.42885 & 10.650675 & 27.61 \\
4 & 17.312489 & 17.01828 & 10.525001 & 27.552 \\
5 & 17.100466 & 17.401932 & 10.807564 & 29.085 \\
Average & 17.0739356 & 17.2290102 & 10.6241784 & 27.8704 \\
Speed Up & 2.9611924974 & 2.9427808685 & 3.7339972943 & 2.7009084907 \\ [1ex]





\hline %inserts single line
\end{tabular}
\end{table}
\pagebreak[4]

\subsection{Valgrind output}
\includegraphics[scale=0.5]{valgrind1.png}\\
\includegraphics[scale=0.5]{valgrind2.png}
\pagebreak
\subsection{Bool and Int research with C file and ASM file}
\lstinputlisting[language=C]{../Sequential/boolInt.c}
\lstinputlisting[language={[x86masm]Assembler}]
{../Sequential/boolInt.s}
\subsection{Bool and Calloc Discussion}
\input{callocbool}
\pagebreak
\subsection{Consumer/Producer and Dynamic Work Allocation Discussion}
\input{dynamic}
\pagebreak
\subsection{Git Graphs and Logs}
\includegraphics[scale=0.35]{git1}\\
\includegraphics[scale=0.35]{git2}\\
\includegraphics[scale=0.35]{git3}
\pagebreak
\subsection{Building the .dat Files}
\lstinputlisting[language=C]{../OpenMP/buildArray.c}
\pagebreak
\subsection{Building the Executables from Source}
\input{building}
\pagebreak
\subsection{Testing Example Shell Script}
\lstinputlisting[language=bash]{../test.sh}
\pagebreak
\section{Glossary}
\glsaddall
\printglossaries
\end{document}